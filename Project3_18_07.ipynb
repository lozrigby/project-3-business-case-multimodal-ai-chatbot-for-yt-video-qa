{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lozrigby/project-3-business-case-multimodal-ai-chatbot-for-yt-video-qa/blob/main/Project3_18_07.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogo0N7utpX4v"
      },
      "source": [
        "#**Project 3**\n",
        "\n",
        "Notebook 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8Ag_DhTp8Cw"
      },
      "source": [
        "###**Downloading the files**\n",
        "\n",
        "Import necessary items"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QW0T-bVBqUfX",
        "outputId": "36799768-c2d2-4d98-aad3-074367c9cc16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-cqm6y2zr\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-cqm6y2zr\n",
            "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (1.25.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1+cu121)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (4.66.4)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (10.1.0)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (0.7.0)\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231117) (2.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.15.4)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231117) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (1.13.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231117) (12.1.105)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->openai-whisper==20231117) (12.5.82)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.7.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231117) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcrjWGJrpXbV",
        "outputId": "eaf44018-4775-494f-e3fa-1605972d934d",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.2.9-py3-none-any.whl (987 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/987.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.8/987.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m563.2/987.7 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m983.0/987.7 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m987.7/987.7 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting langchain-core<0.3.0,>=0.2.20 (from langchain)\n",
            "  Downloading langchain_core-0.2.21-py3-none-any.whl (372 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m372.0/372.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.90-py3-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.7/134.7 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.8.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.20->langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain) (24.1)\n",
            "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.7.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.20->langchain)\n",
            "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
            "Installing collected packages: orjson, jsonpointer, jsonpatch, langsmith, langchain-core, langchain-text-splitters, langchain\n",
            "Successfully installed jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.2.9 langchain-core-0.2.21 langchain-text-splitters-0.2.2 langsmith-0.1.90 orjson-3.10.6\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.1.17-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3.0,>=0.2.20 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.2.21)\n",
            "Collecting openai<2.0.0,>=1.32.0 (from langchain-openai)\n",
            "  Downloading openai-1.35.14-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.5/328.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (0.1.90)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.20->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai<2.0.0,>=1.32.0->langchain-openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.32.0->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.32.0->langchain-openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.32.0->langchain-openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.20->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3.0,>=0.2.20->langchain-openai) (3.10.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.20->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3.0,>=0.2.20->langchain-openai) (2.20.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.0.7)\n",
            "Installing collected packages: h11, httpcore, httpx, openai, langchain-openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 langchain-openai-0.1.17 openai-1.35.14\n",
            "Collecting yt_dlp==2024.4.9\n",
            "  Downloading yt_dlp-2024.4.9-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting brotli (from yt_dlp==2024.4.9)\n",
            "  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from yt_dlp==2024.4.9) (2024.7.4)\n",
            "Collecting mutagen (from yt_dlp==2024.4.9)\n",
            "  Downloading mutagen-1.47.0-py3-none-any.whl (194 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycryptodomex (from yt_dlp==2024.4.9)\n",
            "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m43.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from yt_dlp==2024.4.9) (2.31.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.17 in /usr/local/lib/python3.10/dist-packages (from yt_dlp==2024.4.9) (2.0.7)\n",
            "Collecting websockets>=12.0 (from yt_dlp==2024.4.9)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt_dlp==2024.4.9) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.31.0->yt_dlp==2024.4.9) (3.7)\n",
            "Installing collected packages: brotli, websockets, pycryptodomex, mutagen, yt_dlp\n",
            "Successfully installed brotli-1.1.0 mutagen-1.47.0 pycryptodomex-3.20.0 websockets-12.0 yt_dlp-2024.4.9\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.7.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2024.5.15)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install langchain-openai\n",
        "!pip install yt_dlp==2024.4.9\n",
        "!pip install tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jjLs0uQppq-F",
        "outputId": "086e9c4f-738c-42a4-ba9e-4c8cfef81e05",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.35.14)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "_giaXbXqARkK",
        "outputId": "654cb18a-e80b-4139-bf6b-363a84007b24"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtube_dl\n",
            "  Downloading youtube_dl-2021.12.17-py2.py3-none-any.whl (1.9 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/1.9 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/1.9 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.9 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m1.8/1.9 MB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: youtube_dl\n",
            "Successfully installed youtube_dl-2021.12.17\n"
          ]
        }
      ],
      "source": [
        "!pip install youtube_dl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjelXmyJrxCj",
        "outputId": "83e43f4d-748b-4685-f6a5-f1853ecf4d21",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "q7sgB0aIPYyP",
        "outputId": "b1bb94df-40b9-4ab3-bff2-cbedc97459c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.2.7-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.31)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.5)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.9)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.2.21)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.90)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.5.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (0.2.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain<0.3.0,>=0.2.7->langchain-community) (2.8.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3.0,>=0.2.12->langchain-community) (24.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.10.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.7.4)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.12->langchain-community) (3.0.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.7->langchain-community) (2.20.1)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "Successfully installed dataclasses-json-0.6.7 langchain-community-0.2.7 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pinecone"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "sDUVKMjKNuFD",
        "outputId": "51745130-6b40-4f5c-d4d3-107b1a235401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pinecone\n",
            "  Downloading pinecone-4.0.0-py3-none-any.whl (214 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/214.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m174.1/214.4 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.4/214.4 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2019.11.17 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2024.7.4)\n",
            "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from pinecone) (4.12.2)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.10/dist-packages (from pinecone) (2.0.7)\n",
            "Installing collected packages: pinecone\n",
            "Successfully installed pinecone-4.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langgraph"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bu-fIxuU5E6r",
        "outputId": "ce3d7dbb-4273-4c4a-ce00-97d6cae3295f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.1.8-py3-none-any.whl (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.4/91.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.3,>=0.2.15 in /usr/local/lib/python3.10/dist-packages (from langgraph) (0.2.21)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.15->langgraph) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.15->langgraph) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.15->langgraph) (0.1.90)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.15->langgraph) (24.1)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.15->langgraph) (2.8.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.2.15->langgraph) (8.5.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.15->langgraph) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.15->langgraph) (3.10.6)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.15->langgraph) (2.31.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.15->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.15->langgraph) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.2.15->langgraph) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.15->langgraph) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.15->langgraph) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.15->langgraph) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.2.15->langgraph) (2024.7.4)\n",
            "Installing collected packages: langgraph\n",
            "Successfully installed langgraph-0.1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnEkHWQSpjiU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import openai\n",
        "import yt_dlp as youtube_dl\n",
        "from yt_dlp import DownloadError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rWOwELHZp4HK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb86519c-60d7-4237-ac58-27f6a03920c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key is set\n",
            "pinecone key is set\n"
          ]
        }
      ],
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get(\"Key_from_ironhack\")\n",
        "openai.api_key = openai_api_key\n",
        "\n",
        "api_key = userdata.get(\"pinecone\")\n",
        "\n",
        "\n",
        "# Verify the API key is set\n",
        "if openai.api_key:\n",
        "    print(\"API key is set\")\n",
        "else:\n",
        "    print(\"API key is not set\")\n",
        "\n",
        "if api_key:\n",
        "    print(\"pinecone key is set\")\n",
        "else:\n",
        "    print(\"pinecone key is not set\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wiu63dPp-Xq"
      },
      "source": [
        "Download a youtube video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoQmi5G8ARkL"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import yt_dlp  # Import yt_dlp instead of youtube_dl\n",
        "from yt_dlp.utils import DownloadError  # Import from yt_dlp\n",
        "\n",
        "# Multiple URLs\n",
        "youtube_urls = [\n",
        "    \"https://www.youtube.com/watch?v=Bl4Feh_Mjvo\", #1\n",
        "    \"https://www.youtube.com/watch?v=gqKaVgQxEJ0\", #2\n",
        "    \"https://www.youtube.com/watch?v=k_pDh_68K6c\", #3\n",
        "    \"https://www.youtube.com/watch?v=goDDnBbJQ4g\", #4\n",
        "    \"https://www.youtube.com/watch?v=RMy_1mO4HLk\", #5\n",
        "    \"https://www.youtube.com/watch?v=ADj95edZc0w\", #6\n",
        "    \"https://www.youtube.com/watch?v=dzDOqrac9Ks\", #7\n",
        "    \"https://www.youtube.com/watch?v=ZMxfDWPXmjc\", #8\n",
        "    \"https://www.youtube.com/watch?v=UbtTv7j1tzU\", #9\n",
        "    \"https://www.youtube.com/watch?v=7AQYw5FOVcw\", #10\n",
        "    \"https://www.youtube.com/watch?v=NirZnqwYfYU\", #11\n",
        "    \"https://www.youtube.com/watch?v=LMZZPneTcP4\", #12\n",
        "    \"https://www.youtube.com/watch?v=khTGx7m3Y8A\", #13\n",
        "    \"https://www.youtube.com/watch?v=o2KzJdbOwMc\", #14\n",
        "    \"https://www.youtube.com/watch?v=FVLZG_oHUIw\", #15\n",
        "    \"https://www.youtube.com/watch?v=6N3OAWIsUOU\", #16\n",
        "    \"https://www.youtube.com/watch?v=6ZYx_1NlYbI\",#17\n",
        "    \"https://www.youtube.com/watch?v=UyPn-QR8A7I\", #18\n",
        "    \"https://www.youtube.com/watch?v=gPCd0xx_OYI\" #19\n",
        "]\n",
        "\n",
        "# Directory to store the downloaded videos\n",
        "output_dir = \"files/audio/lectures\"\n",
        "\n",
        "# Check if the output directory exists, if not create it\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "# Configuration for youtube-dl\n",
        "ydl_config = {\n",
        "    \"format\": \"bestaudio/best\",\n",
        "    \"postprocessors\": [\n",
        "        {\n",
        "            \"key\": \"FFmpegExtractAudio\",\n",
        "            \"preferredcodec\": \"mp3\",\n",
        "            \"preferredquality\": \"192\",\n",
        "        }\n",
        "    ],\n",
        "    \"outtmpl\": os.path.join(output_dir, \"%(title)s.%(ext)s\"),\n",
        "    \"verbose\": True,\n",
        "    #\"ffmpeg_location\": \"/path/to/ffmpeg\",  # Specify the path to ffmpeg if not in PATH\n",
        "    \"continuedl\": False,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if the output directory exists, if not create it\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir)\n",
        "\n",
        "for youtube_url in youtube_urls:\n",
        "    # Print a message indicating which video is being downloaded\n",
        "    print(f\"Downloading video from {youtube_url}\")\n",
        "\n",
        "    # Try to download the video using the specified configuration\n",
        "    # If a DownloadError occurs, attempt to download the video again\n",
        "    try:\n",
        "        with yt_dlp.YoutubeDL(ydl_config) as ydl:  # Use yt_dlp instead of youtube_dl\n",
        "            ydl.download([youtube_url])\n",
        "    except DownloadError as e:\n",
        "        print(f\"Error downloading {youtube_url}: {str(e)}\")\n",
        "        # Get the expected filename\n",
        "        with yt_dlp.YoutubeDL(ydl_config) as ydl:  # Use yt_dlp here as well\n",
        "            info_dict = ydl.extract_info(youtube_url, download=False)\n",
        "            filename = ydl.prepare_filename(info_dict)\n",
        "        # Remove partially downloaded files\n",
        "        for f in glob.glob(filename + '*'):\n",
        "            os.remove(f)\n",
        "        # Retry the download\n",
        "        with yt_dlp.YoutubeDL(ydl_config) as ydl:  # And here\n",
        "            ydl.download([youtube_url])\n",
        "\n",
        "    # Print a message indicating that the video has been downloaded\n",
        "    print(f\"Video downloaded successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "GkKo0jVlBgpb",
        "outputId": "5b583816-20f9-40c3-dca7-2a345b3c5fd7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': 'files/audio/lectures/%(title)s.%(ext)s', 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading video from https://www.youtube.com/watch?v=Bl4Feh_Mjvo\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=Bl4Feh_Mjvo\n",
            "[youtube] Bl4Feh_Mjvo: Downloading webpage\n",
            "[youtube] Bl4Feh_Mjvo: Downloading ios player API JSON\n",
            "[youtube] Bl4Feh_Mjvo: Downloading android player API JSON\n",
            "[youtube] Bl4Feh_Mjvo: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] Bl4Feh_Mjvo: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = h5rONMoPibo9QSkuYGD ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] Bl4Feh_Mjvo: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = bw9pTKaf4rVQPwZr7zD ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] Bl4Feh_Mjvo: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] Bl4Feh_Mjvo: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr2---sn-q4fl6n6d.googlevideo.com/videoplayback?expire=1721321856&ei=IPWYZuvgHPm2sfIP34mcsAs&ip=34.125.104.111&id=o-AMPLd2DvKvaQCbA5TkZ6wWVU1ywkcwUjUpkbaxh1b4xE&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=bh&mm=31%2C26&mn=sn-q4fl6n6d%2Csn-a5mekn6z&ms=au%2Conr&mv=m&mvi=2&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=76420380&dur=4721.963&lmt=1684533102544215&mt=1721299967&fvip=1&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhAMc2cnxGH4WaS7IwmVZim9M8jF9C_u9nN57dh2pLr_q2AiBCy_MQVQNnsaGfHQ6f3_qKmPicBOoPABdTOEcgbIijiA%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRgIhAOhXQ6J1QCaek11iz-zG1az2vMlYqEHVL6iiJT9lqmOBAiEA-ecOmuzEb22qq-n3I1fQ3J-UkAq_F_RxPdQ0hksXZnk%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Introduction I 2022 I Lecture 1.m4a\n",
            "[download] 100% of   72.88MiB in 00:00:04 at 14.69MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Introduction I 2022 I Lecture 1.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Introduction I 2022 I Lecture 1.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Introduction I 2022 I Lecture 1.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Introduction I 2022 I Lecture 1.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Introduction I 2022 I Lecture 1.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Introduction I 2022 I Lecture 1.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Introduction I 2022 I Lecture 1.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Introduction I 2022 I Lecture 1.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=gqKaVgQxEJ0\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=gqKaVgQxEJ0\n",
            "[youtube] gqKaVgQxEJ0: Downloading webpage\n",
            "[youtube] gqKaVgQxEJ0: Downloading ios player API JSON\n",
            "[youtube] gqKaVgQxEJ0: Downloading android player API JSON\n",
            "[youtube] gqKaVgQxEJ0: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] gqKaVgQxEJ0: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = KXT7hNbtRXlBhjq2tnj ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] gqKaVgQxEJ0: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = cDayLGiDKurFdi8Z2XR ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] gqKaVgQxEJ0: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] gqKaVgQxEJ0: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr2---sn-q4fl6ns7.googlevideo.com/videoplayback?expire=1721321940&ei=dPWYZp-oCt7XsfIPis-RmAU&ip=34.125.104.111&id=o-AKKANRv4qWIMGdfX-f2cF9PqlJ94XqYW1apF7DXY_d1F&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=u4&mm=31%2C29&mn=sn-q4fl6ns7%2Csn-q4flrnss&ms=au%2Crdu&mv=m&mvi=2&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=58182687&dur=3595.052&lmt=1691031040526000&mt=1721299967&fvip=2&keepalive=yes&c=IOS&txp=5318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhANnD2tl8cLdG5xcmT8IUDi6l63PLrTQfe5EWSx-vwTB_AiBdK2Rz4a_xtwp_9eCTeU6Mxy5SiQKWwVuYHqotKTgQMQ%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRAIgRLg8ylQSeGXht-OZQa67D9NPPWLAA8OUyT8gIXnUrscCIGr6YE1beQVFL6VBfNBqmo9aqlee7-CCtu_E106HxIRX\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Supervised learning setup, LMS I 2022 I Lecture 2.m4a\n",
            "[download] 100% of   55.49MiB in 00:00:01 at 33.69MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Supervised learning setup, LMS I 2022 I Lecture 2.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Supervised learning setup, LMS I 2022 I Lecture 2.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Supervised learning setup, LMS I 2022 I Lecture 2.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Supervised learning setup, LMS I 2022 I Lecture 2.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Supervised learning setup, LMS I 2022 I Lecture 2.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Supervised learning setup, LMS I 2022 I Lecture 2.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Supervised learning setup, LMS I 2022 I Lecture 2.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Supervised learning setup, LMS I 2022 I Lecture 2.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=k_pDh_68K6c\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=k_pDh_68K6c\n",
            "[youtube] k_pDh_68K6c: Downloading webpage\n",
            "[youtube] k_pDh_68K6c: Downloading ios player API JSON\n",
            "[youtube] k_pDh_68K6c: Downloading android player API JSON\n",
            "[youtube] k_pDh_68K6c: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] k_pDh_68K6c: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = PnbWn_pS8VIPAcUYh-w ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] k_pDh_68K6c: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = A24pGZrXeciY6xvmvZV ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] k_pDh_68K6c: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] k_pDh_68K6c: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr1---sn-q4flrney.googlevideo.com/videoplayback?expire=1721322001&ei=sfWYZpLWLdmBsfIPip6ZqAU&ip=34.125.104.111&id=o-AFEsP2VSl0Pfvx7CQ40tgI_uv7WW0UujCu_l_jcJmsCN&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=97&mm=31%2C26&mn=sn-q4flrney%2Csn-a5m7lnl6&ms=au%2Conr&mv=m&mvi=1&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=70868890&dur=4378.934&lmt=1691080668555546&mt=1721299967&fvip=4&keepalive=yes&c=IOS&txp=5318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhAML8K0Dqn8UnIm2KuAFKgc6ckzOQc-DnquFvPBzeIrpJAiBRmk-xlhrti-ruLSKcYW9lDSe0-gmxFlvXgupEMc7OlA%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRAIgK3YIfJsSd3aXWkDC6tOgs6ZE_GNEXUMwOTNQ3mPIotICICj986F6pqrZHG6-XtDS413EUC_PBTubqdoTwv58q8lv\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 I Weighted Least Squares, Logistic regression, Newton's Method I 2022 I Lecture 3.m4a\n",
            "[download] 100% of   67.59MiB in 00:00:02 at 33.31MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 I Weighted Least Squares, Logistic regression, Newton's Method I 2022 I Lecture 3.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 I Weighted Least Squares, Logistic regression, Newton'\"'\"'s Method I 2022 I Lecture 3.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 I Weighted Least Squares, Logistic regression, Newton'\"'\"'s Method I 2022 I Lecture 3.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 I Weighted Least Squares, Logistic regression, Newton'\"'\"'s Method I 2022 I Lecture 3.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 I Weighted Least Squares, Logistic regression, Newton's Method I 2022 I Lecture 3.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 I Weighted Least Squares, Logistic regression, Newton'\"'\"'s Method I 2022 I Lecture 3.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 I Weighted Least Squares, Logistic regression, Newton'\"'\"'s Method I 2022 I Lecture 3.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 I Weighted Least Squares, Logistic regression, Newton's Method I 2022 I Lecture 3.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=goDDnBbJQ4g\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=goDDnBbJQ4g\n",
            "[youtube] goDDnBbJQ4g: Downloading webpage\n",
            "[youtube] goDDnBbJQ4g: Downloading ios player API JSON\n",
            "[youtube] goDDnBbJQ4g: Downloading android player API JSON\n",
            "[youtube] goDDnBbJQ4g: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] goDDnBbJQ4g: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = iCwbtCtm7sRls9c42Hs ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] goDDnBbJQ4g: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = hiYA0SSKPg-jmI6ddyX ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] goDDnBbJQ4g: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] goDDnBbJQ4g: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr3---sn-q4fl6nsk.googlevideo.com/videoplayback?expire=1721322076&ei=_PWYZseiNMKxsfIPgqm7mAU&ip=34.125.104.111&id=o-AMePH_B4ZZa5gAFfvXo9-hIHj2ttkn5tPZ6thz64DCKt&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=Xq&mm=31%2C26&mn=sn-q4fl6nsk%2Csn-a5mekn6k&ms=au%2Conr&mv=m&mvi=3&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=75167587&dur=4644.547&lmt=1684533305153273&mt=1721300211&fvip=1&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhAI31kxJpSgS6F1NxaovSbatUkIrGcgv_-n-wltYGDGf3AiBbbgiYEm0LJ0aYdlOIkA1VV-3DYCupB6gCCkjud4oq-A%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRQIhAO4l5XRzqx1gEmquOIPTiysH5SwIm_puBErGxOJFbMHqAiA_UC_O6JBJ4xkqSG0ReKHjJy9PXTJ5iFYEjN3VpfTzbg%3D%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Exponential family, Generalized Linear Models I 2022 I Lecture 4.m4a\n",
            "[download] 100% of   71.69MiB in 00:00:02 at 34.20MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Exponential family, Generalized Linear Models I 2022 I Lecture 4.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Exponential family, Generalized Linear Models I 2022 I Lecture 4.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Exponential family, Generalized Linear Models I 2022 I Lecture 4.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Exponential family, Generalized Linear Models I 2022 I Lecture 4.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Exponential family, Generalized Linear Models I 2022 I Lecture 4.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Exponential family, Generalized Linear Models I 2022 I Lecture 4.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Exponential family, Generalized Linear Models I 2022 I Lecture 4.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Exponential family, Generalized Linear Models I 2022 I Lecture 4.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=RMy_1mO4HLk\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=RMy_1mO4HLk\n",
            "[youtube] RMy_1mO4HLk: Downloading webpage\n",
            "[youtube] RMy_1mO4HLk: Downloading ios player API JSON\n",
            "[youtube] RMy_1mO4HLk: Downloading android player API JSON\n",
            "[youtube] RMy_1mO4HLk: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] RMy_1mO4HLk: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = X8HaLpCs-Iap3yHuWUJ ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] RMy_1mO4HLk: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = 5DXNDKV2mdKHO8Y-z7h ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] RMy_1mO4HLk: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] RMy_1mO4HLk: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr5---sn-q4flrney.googlevideo.com/videoplayback?expire=1721322155&ei=S_aYZsWdOf2KsfIPz864wAU&ip=34.125.104.111&id=o-AATUyIbeUUs-NjxoDbABKfon6rszfuftwbEPTOfdeH26&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=yX&mm=31%2C26&mn=sn-q4flrney%2Csn-a5mlrnlz&ms=au%2Conr&mv=m&mvi=5&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=85998951&dur=5313.816&lmt=1683571901119535&mt=1721300211&fvip=2&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRgIhALmE6gE3Lnzw_J2R64pCDOdAlbrVB8RdHqLk5wF4Y-eTAiEAhw3Uh8kwBdw88vfQxqKYjFHK2td8OebklE8AxU6tamg%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRQIgRXgpJlZ9EtnmvimTfzvxszyBOtbioTjCg-lDCb4h9xgCIQDCJyZz__MOq7I3Hjr9g7N2-nhlRkfMCkavfUpcNYjVjg%3D%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Gaussian discriminant analysis, Naive Bayes I 2022 I Lecture 5.m4a\n",
            "[download] 100% of   82.01MiB in 00:00:09 at 8.31MiB/s   \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Gaussian discriminant analysis, Naive Bayes I 2022 I Lecture 5.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Gaussian discriminant analysis, Naive Bayes I 2022 I Lecture 5.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Gaussian discriminant analysis, Naive Bayes I 2022 I Lecture 5.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Gaussian discriminant analysis, Naive Bayes I 2022 I Lecture 5.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Gaussian discriminant analysis, Naive Bayes I 2022 I Lecture 5.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Gaussian discriminant analysis, Naive Bayes I 2022 I Lecture 5.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Gaussian discriminant analysis, Naive Bayes I 2022 I Lecture 5.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Gaussian discriminant analysis, Naive Bayes I 2022 I Lecture 5.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=ADj95edZc0w\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=ADj95edZc0w\n",
            "[youtube] ADj95edZc0w: Downloading webpage\n",
            "[youtube] ADj95edZc0w: Downloading ios player API JSON\n",
            "[youtube] ADj95edZc0w: Downloading android player API JSON\n",
            "[youtube] ADj95edZc0w: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] ADj95edZc0w: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = fR1iZIM6c9i5Z5KVDGh ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] ADj95edZc0w: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = vGm_tKehM_vWNfdfOGR ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] ADj95edZc0w: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] ADj95edZc0w: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr3---sn-q4flrnsk.googlevideo.com/videoplayback?expire=1721322283&ei=y_aYZvi-D-bAsfIP7dWP0AM&ip=34.125.104.111&id=o-AAQtOjmhGXP5vTXxO2jlwiVL487-R4F5YNAYAwt8GnY0&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=a0&mm=31%2C26&mn=sn-q4flrnsk%2Csn-a5mekn6k&ms=au%2Conr&mv=m&mvi=3&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=80981422&dur=5003.783&lmt=1684533410100534&mt=1721300456&fvip=1&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRgIhAPWlEgyVHiCA8pOPSJrp5vC8okTXpjvcPSV4g2tzXcnuAiEA6Z97818jWAvci_57BuR81vi9r-RiebXuwgcsrO8IxTw%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRAIgCYgPhUHJvbrrS8iRa8CdgCLI6EhSXmfK5LSplsbefbwCIAQHKCknV3NXtHkBjtrWLU78vaQW-_EFHcYUUnPwfYxm\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Naive Bayes, Laplace Smoothing I 2022 I Lecture 6.m4a\n",
            "[download] 100% of   77.23MiB in 00:00:02 at 26.46MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Naive Bayes, Laplace Smoothing I 2022 I Lecture 6.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Naive Bayes, Laplace Smoothing I 2022 I Lecture 6.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Naive Bayes, Laplace Smoothing I 2022 I Lecture 6.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Naive Bayes, Laplace Smoothing I 2022 I Lecture 6.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Naive Bayes, Laplace Smoothing I 2022 I Lecture 6.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Naive Bayes, Laplace Smoothing I 2022 I Lecture 6.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Naive Bayes, Laplace Smoothing I 2022 I Lecture 6.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Naive Bayes, Laplace Smoothing I 2022 I Lecture 6.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=dzDOqrac9Ks\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=dzDOqrac9Ks\n",
            "[youtube] dzDOqrac9Ks: Downloading webpage\n",
            "[youtube] dzDOqrac9Ks: Downloading ios player API JSON\n",
            "[youtube] dzDOqrac9Ks: Downloading android player API JSON\n",
            "[youtube] dzDOqrac9Ks: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] dzDOqrac9Ks: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = d7t32nSYkFleDh6nJdI ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] dzDOqrac9Ks: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = wVyhiZheOqBnQf4Mwkk ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] dzDOqrac9Ks: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] dzDOqrac9Ks: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr2---sn-q4fl6nsd.googlevideo.com/videoplayback?expire=1721322369&ei=IfeYZqyZDZX6sfIPwq6dwAU&ip=34.125.104.111&id=o-AORJC2AkGrDm0-38LoIL8TzaKw0tsMc4h9XnWipHkIuM&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=Uc&mm=31%2C29&mn=sn-q4fl6nsd%2Csn-q4flrnl6&ms=au%2Crdu&mv=m&mvi=2&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=85831729&dur=5303.483&lmt=1684533461978383&mt=1721300456&fvip=1&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIgRugBJfhdsWohxl42sgY-2v0ALrwfFlEp4y-dN9xa-A4CIQDQUvtKjYJGSxFNVPBx49CG6RBJR_aPsptULkrsxZ-SKw%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRQIgbfA3jBW8zPkoO6NnLYtnlTIX6vVo8EEQQI6n36fteaUCIQC0HKqnScX-B_tqhkcoEcLz1ctAC8f8A0k7_1KygkDUiA%3D%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Kernels I 2022 I Lecture 7.m4a\n",
            "[download] 100% of   81.86MiB in 00:00:03 at 22.71MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Kernels I 2022 I Lecture 7.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Kernels I 2022 I Lecture 7.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Kernels I 2022 I Lecture 7.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Kernels I 2022 I Lecture 7.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Kernels I 2022 I Lecture 7.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Kernels I 2022 I Lecture 7.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Kernels I 2022 I Lecture 7.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Kernels I 2022 I Lecture 7.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=ZMxfDWPXmjc\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=ZMxfDWPXmjc\n",
            "[youtube] ZMxfDWPXmjc: Downloading webpage\n",
            "[youtube] ZMxfDWPXmjc: Downloading ios player API JSON\n",
            "[youtube] ZMxfDWPXmjc: Downloading android player API JSON\n",
            "[youtube] ZMxfDWPXmjc: Downloading player d60b0ef9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] ZMxfDWPXmjc: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = iBfAmHQ6HdQwBhoC ; player = https://www.youtube.com/s/player/d60b0ef9/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] ZMxfDWPXmjc: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = R-gK_MfK17g_GdMU ; player = https://www.youtube.com/s/player/d60b0ef9/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] ZMxfDWPXmjc: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] ZMxfDWPXmjc: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr1---sn-q4flrnl6.googlevideo.com/videoplayback?expire=1721322460&ei=fPeYZrnLEeLYsfIPm9OP0As&ip=34.125.104.111&id=o-AHMc_eqZbSTZ5MmEy19Ka4e88YEneNWIT630bYGNcMvq&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=TZ&mm=31%2C26&mn=sn-q4flrnl6%2Csn-a5mlrnlz&ms=au%2Conr&mv=m&mvi=1&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=68227509&dur=4215.721&lmt=1691531692769922&mt=1721300456&fvip=2&keepalive=yes&c=IOS&txp=5318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIgThgKel4QR8xNfuBlYi6FiJyxDP93_idQp-VrrwO4BL4CIQD1xCyvHGLe16zdh2Odz26Q_ILgj7XDysIzrY7Oe93_kA%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRgIhAPO8Dti62zBmN89myWmvs1FeGeHibdWLycUIJCBLxK8UAiEAquI2ZxzX_5gNK-4ig1YMMZ4wAY_4FQ9A2MhHgA-wctc%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 1 I 2022 I Lecture 8.m4a\n",
            "[download] 100% of   65.07MiB in 00:00:02 at 24.86MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 1 I 2022 I Lecture 8.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 1 I 2022 I Lecture 8.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 1 I 2022 I Lecture 8.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 1 I 2022 I Lecture 8.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 1 I 2022 I Lecture 8.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 1 I 2022 I Lecture 8.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 1 I 2022 I Lecture 8.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 1 I 2022 I Lecture 8.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=UbtTv7j1tzU\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=UbtTv7j1tzU\n",
            "[youtube] UbtTv7j1tzU: Downloading webpage\n",
            "[youtube] UbtTv7j1tzU: Downloading ios player API JSON\n",
            "[youtube] UbtTv7j1tzU: Downloading android player API JSON\n",
            "[youtube] UbtTv7j1tzU: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] UbtTv7j1tzU: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = TV6UBI1fInORrvJe2GH ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] UbtTv7j1tzU: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = R62m7MJsXaSnuuq_WpQ ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] UbtTv7j1tzU: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] UbtTv7j1tzU: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr1---sn-q4fl6n6z.googlevideo.com/videoplayback?expire=1721322533&ei=xfeYZu3yEfnZsfIP3aKwoAI&ip=34.125.104.111&id=o-ANj7au2_yRU0CUSepgbg7yA2xf49bAmSxfGP33NoE0p3&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=EP&mm=31%2C29&mn=sn-q4fl6n6z%2Csn-q4fzen7s&ms=au%2Crdu&mv=m&mvi=1&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=86933823&dur=5371.587&lmt=1684533557984168&mt=1721300692&fvip=5&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhAI1yXYGfgVtIlx8AslB34lJCmsvffM2aj8dtOotbYpMWAiBwMa_wNrTbISy3MBM4vPtkIPI4Km1oFx4Q2b81IMA87A%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRQIhAKl9NwOnSN8jPVRG5sbYHSugTpTTn6J4SZIoWcRqpEENAiAnbUXuOH_mY80NXPR_6a_sf0r7HXZxYduT7L5oEIUmIA%3D%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 2 (backprop) I 2022 I Lecture 9.m4a\n",
            "[download] 100% of   82.91MiB in 00:00:03 at 24.18MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 2 (backprop) I 2022 I Lecture 9.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 2 (backprop) I 2022 I Lecture 9.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 2 (backprop) I 2022 I Lecture 9.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 2 (backprop) I 2022 I Lecture 9.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 2 (backprop) I 2022 I Lecture 9.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 2 (backprop) I 2022 I Lecture 9.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 2 (backprop) I 2022 I Lecture 9.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Neural Networks 2 (backprop) I 2022 I Lecture 9.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=7AQYw5FOVcw\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=7AQYw5FOVcw\n",
            "[youtube] 7AQYw5FOVcw: Downloading webpage\n",
            "[youtube] 7AQYw5FOVcw: Downloading ios player API JSON\n",
            "[youtube] 7AQYw5FOVcw: Downloading android player API JSON\n",
            "[youtube] 7AQYw5FOVcw: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] 7AQYw5FOVcw: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = C7fIOQIlE16OR5M9jPw ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] 7AQYw5FOVcw: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = B734LWEAP0ezmjaxx9y ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] 7AQYw5FOVcw: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] 7AQYw5FOVcw: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr5---sn-q4fl6n66.googlevideo.com/videoplayback?expire=1721322625&ei=IfiYZvSvDbf7sfIP_P-cwAU&ip=34.125.104.111&id=o-AFi33ipeO1FXBR6o4gmdEFUFPiCuHA5iPL8C-d-rFCm3&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=R5&mm=31%2C26&mn=sn-q4fl6n66%2Csn-a5mekn6r&ms=au%2Conr&mv=m&mvi=5&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=87756531&dur=5422.416&lmt=1684533576521759&mt=1721300692&fvip=2&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIgPU8ith46pIa2H-z7-EEESLLpQafc5q8-NBOkk4EDUtACIQDc-_e2gUGO_G4IB0Z-IwWoaDBoQItn2cMrHeZxdJ0_pQ%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRgIhALEQ07LQNPaAZZwAzu4YXbPSNh6Po5n4qDCf9TtMn-PZAiEAxd5095sOCdBV2YGuOelVtVPrzO4tR2fu0ZOSBoJ0yUk%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Bias - Variance, Regularization I 2022 I Lecture 10.m4a\n",
            "[download] 100% of   83.69MiB in 00:00:03 at 25.92MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Bias - Variance, Regularization I 2022 I Lecture 10.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Bias - Variance, Regularization I 2022 I Lecture 10.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Bias - Variance, Regularization I 2022 I Lecture 10.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Bias - Variance, Regularization I 2022 I Lecture 10.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Bias - Variance, Regularization I 2022 I Lecture 10.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Bias - Variance, Regularization I 2022 I Lecture 10.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Bias - Variance, Regularization I 2022 I Lecture 10.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Bias - Variance, Regularization I 2022 I Lecture 10.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=NirZnqwYfYU\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=NirZnqwYfYU\n",
            "[youtube] NirZnqwYfYU: Downloading webpage\n",
            "[youtube] NirZnqwYfYU: Downloading ios player API JSON\n",
            "[youtube] NirZnqwYfYU: Downloading android player API JSON\n",
            "[youtube] NirZnqwYfYU: Downloading player d60b0ef9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] NirZnqwYfYU: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = mSyj6hvmew7ZBc4d ; player = https://www.youtube.com/s/player/d60b0ef9/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] NirZnqwYfYU: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = lmht5gT6BqkTkPao ; player = https://www.youtube.com/s/player/d60b0ef9/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] NirZnqwYfYU: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] NirZnqwYfYU: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr2---sn-q4fl6n66.googlevideo.com/videoplayback?expire=1721322718&ei=fviYZsjtD6nGsfIP9s2U6Ag&ip=34.125.104.111&id=o-AOWHjO2rYVRdjwMS9GfqRBSrr9HV0Sn1DTLAOgP7nOTn&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=i3&mm=31%2C26&mn=sn-q4fl6n66%2Csn-a5mekn6z&ms=au%2Conr&mv=m&mvi=2&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=86576848&dur=5349.528&lmt=1684533628878631&mt=1721300692&fvip=1&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRAIgWXueu56bwB6k4WidT4IJMLcyb4fJsuvW0yANRKBsTlUCIHJWxd-6MGGI1MzHhO7zqi5AscUN0G9IYUR3-I3Zv3jX&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRgIhAKQoWOKrr8u6lJ6-KYAcLeV-Orohs_xycvs4fGKTo7JsAiEA-jraRxECeR23K7R0XWtPGivgAoYQlPBiCdD3i6yrDyQ%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Feature ⧸ Model selection, ML Advice I 2022 I Lecture 11.m4a\n",
            "[download] 100% of   82.57MiB in 00:00:02 at 37.20MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Feature ⧸ Model selection, ML Advice I 2022 I Lecture 11.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Feature ⧸ Model selection, ML Advice I 2022 I Lecture 11.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Feature ⧸ Model selection, ML Advice I 2022 I Lecture 11.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Feature ⧸ Model selection, ML Advice I 2022 I Lecture 11.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Feature ⧸ Model selection, ML Advice I 2022 I Lecture 11.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Feature ⧸ Model selection, ML Advice I 2022 I Lecture 11.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Feature ⧸ Model selection, ML Advice I 2022 I Lecture 11.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Feature ⧸ Model selection, ML Advice I 2022 I Lecture 11.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=LMZZPneTcP4\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=LMZZPneTcP4\n",
            "[youtube] LMZZPneTcP4: Downloading webpage\n",
            "[youtube] LMZZPneTcP4: Downloading ios player API JSON\n",
            "[youtube] LMZZPneTcP4: Downloading android player API JSON\n",
            "[youtube] LMZZPneTcP4: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] LMZZPneTcP4: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = kw32EF8nk-Z7l1l29R6 ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] LMZZPneTcP4: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = GJXbAfYgfZGmz8zPgV5 ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] LMZZPneTcP4: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] LMZZPneTcP4: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr1---sn-q4fl6nz6.googlevideo.com/videoplayback?expire=1721322809&ei=2fiYZrinHd2EsfIPptOluAU&ip=34.125.104.111&id=o-AF8tDzrzRolsqpETeFstB5kH5vX4U3VIgqZAWDjoj7Yc&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=F0&mm=31%2C29&mn=sn-q4fl6nz6%2Csn-q4fzenee&ms=au%2Crdu&mv=m&mvi=1&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=84151882&dur=5199.690&lmt=1684533492550621&mt=1721300930&fvip=4&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRAIgV7UyaKs0qwhyWrg2DstHGaGo6qbsYE_UwvelCRk9nCcCIDdLSttNsTiz-qbeLQSQIaeGNGp2hOAVfrUzNG19sPOd&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRQIgW730mnauJFZu8HxtYu8PjQbdN56MqCNWzuKYdEhiHCQCIQDazqUrvtwlFXKtuPApFr3y3qzFxC26kuft3089XXX58g%3D%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 I K-Means, GMM (non EM), Expectation Maximization I 2022 I Lecture 12.m4a\n",
            "[download] 100% of   80.25MiB in 00:00:03 at 25.30MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 I K-Means, GMM (non EM), Expectation Maximization I 2022 I Lecture 12.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 I K-Means, GMM (non EM), Expectation Maximization I 2022 I Lecture 12.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 I K-Means, GMM (non EM), Expectation Maximization I 2022 I Lecture 12.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 I K-Means, GMM (non EM), Expectation Maximization I 2022 I Lecture 12.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 I K-Means, GMM (non EM), Expectation Maximization I 2022 I Lecture 12.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 I K-Means, GMM (non EM), Expectation Maximization I 2022 I Lecture 12.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 I K-Means, GMM (non EM), Expectation Maximization I 2022 I Lecture 12.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 I K-Means, GMM (non EM), Expectation Maximization I 2022 I Lecture 12.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=khTGx7m3Y8A\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=khTGx7m3Y8A\n",
            "[youtube] khTGx7m3Y8A: Downloading webpage\n",
            "[youtube] khTGx7m3Y8A: Downloading ios player API JSON\n",
            "[youtube] khTGx7m3Y8A: Downloading android player API JSON\n",
            "[youtube] khTGx7m3Y8A: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] khTGx7m3Y8A: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = dA4xb2gxRtybQFroYhZ ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] khTGx7m3Y8A: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = Z7W8Seb4cXcZYnz43yt ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] khTGx7m3Y8A: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] khTGx7m3Y8A: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr2---sn-q4flrnsl.googlevideo.com/videoplayback?expire=1721322899&ei=M_mYZoC2NvTlsfIP6OabkAU&ip=34.125.104.111&id=o-AHcEd0DSxMcV_BJARSlPE-G1zVhHeHMrjJytVRuu_K4w&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=7h&mm=31%2C26&mn=sn-q4flrnsl%2Csn-a5meknsy&ms=au%2Conr&mv=m&mvi=2&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=85318681&dur=5271.788&lmt=1691938675233328&mt=1721300930&fvip=5&keepalive=yes&c=IOS&txp=5308224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIgRE2PlOhmrml4Zj0qzGq_IQ24Q8Z2Gs3619wuuHpfI_0CIQC4oyFysq3LxMNvE2Et2vXbO782ZIxPL4odkRlXgrQPVA%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRAIgOr6PpCvFy0Upige4Ig6_aH7xz66vqAGzIQzcp7mRL34CIEY2U_GMQ7EJCWQpHEW6o7AgeKOnuDyZHzt6R7952g9a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I GMM (EM) I 2022 I Lecture 13.m4a\n",
            "[download] 100% of   81.37MiB in 00:00:02 at 30.08MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I GMM (EM) I 2022 I Lecture 13.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I GMM (EM) I 2022 I Lecture 13.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I GMM (EM) I 2022 I Lecture 13.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I GMM (EM) I 2022 I Lecture 13.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I GMM (EM) I 2022 I Lecture 13.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I GMM (EM) I 2022 I Lecture 13.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I GMM (EM) I 2022 I Lecture 13.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I GMM (EM) I 2022 I Lecture 13.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=o2KzJdbOwMc\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=o2KzJdbOwMc\n",
            "[youtube] o2KzJdbOwMc: Downloading webpage\n",
            "[youtube] o2KzJdbOwMc: Downloading ios player API JSON\n",
            "[youtube] o2KzJdbOwMc: Downloading android player API JSON\n",
            "[youtube] o2KzJdbOwMc: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] o2KzJdbOwMc: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = xAOvFPBeVo-TFPjJt7R ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] o2KzJdbOwMc: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = t1i7P4SuFFmPrqJlzYE ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] o2KzJdbOwMc: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] o2KzJdbOwMc: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr5---sn-q4fzen7s.googlevideo.com/videoplayback?expire=1721322989&ei=jfmYZs-SM_v4sfIP0qi9oAU&ip=34.125.104.111&id=o-AGWIQmLj_GDxGCl3p7z6poLaaiExr1Z4agYDcONN-W1P&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=hI&mm=31%2C26&mn=sn-q4fzen7s%2Csn-a5msen7z&ms=au%2Conr&mv=m&mvi=5&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=86640426&dur=5353.453&lmt=1692098756505876&mt=1721300930&fvip=2&keepalive=yes&c=IOS&txp=5308224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRAIgUxqCwU4Zujgfq6h1nED91CgAavAgiSsgLd7MjfoOJlsCICwVcfYt8h_9mWI4v3auuJ9Jun7OVKoh9JoZi1NyAevM&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRAIgSARO-OqeDXPnZXKBOiVGFokV7kU8_1XMxfhyfReNsHMCIBTzIzbQ3jpr0FG0cBAK7I8ml9fd69K53fZMXOC3neq1\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Factor Analysis⧸PCA I 2022 I Lecture 14.m4a\n",
            "[download] 100% of   82.63MiB in 00:00:04 at 19.05MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Factor Analysis⧸PCA I 2022 I Lecture 14.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Factor Analysis⧸PCA I 2022 I Lecture 14.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Factor Analysis⧸PCA I 2022 I Lecture 14.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Factor Analysis⧸PCA I 2022 I Lecture 14.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Factor Analysis⧸PCA I 2022 I Lecture 14.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Factor Analysis⧸PCA I 2022 I Lecture 14.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Factor Analysis⧸PCA I 2022 I Lecture 14.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Factor Analysis⧸PCA I 2022 I Lecture 14.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=FVLZG_oHUIw\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=FVLZG_oHUIw\n",
            "[youtube] FVLZG_oHUIw: Downloading webpage\n",
            "[youtube] FVLZG_oHUIw: Downloading ios player API JSON\n",
            "[youtube] FVLZG_oHUIw: Downloading android player API JSON\n",
            "[youtube] FVLZG_oHUIw: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] FVLZG_oHUIw: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = Fk7y7CRThKF2Moc7Orr ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] FVLZG_oHUIw: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = 3AQ-6SafkFDStvOarYB ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] FVLZG_oHUIw: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] FVLZG_oHUIw: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr3---sn-q4fl6nsy.googlevideo.com/videoplayback?expire=1721323083&ei=6_mYZvinFPLAsfIP99iz2AE&ip=34.125.104.111&id=o-AKR11zgD_IpZGODpQTR7V2V5RTkw0EV3xHSzA0nGgBrr&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=3Q&mm=31%2C26&mn=sn-q4fl6nsy%2Csn-a5m7lnl6&ms=au%2Conr&mv=m&mvi=3&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=74571174&dur=4607.697&lmt=1692176532133155&mt=1721301170&fvip=1&keepalive=yes&c=IOS&txp=5318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIhANsk3gEQai5oLyo57bmTLSqk_D-oPZOWUHupc_IlfKp1AiAtv_LgmhkrtAjyOhf0aZyRdzd1tOR09jMzxRDKsSr9uw%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRQIgHJqEx19USVbZbhlX76-1IhQa7SGoHKxm10Qx2vCMHzkCIQCmWk_MktC8E4NVed7TeNfKmfOVzFsCOJikbh8K3KOg3w%3D%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I PCA⧸ICA I 2022 I Lecture 15.m4a\n",
            "[download] 100% of   71.12MiB in 00:00:03 at 20.65MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I PCA⧸ICA I 2022 I Lecture 15.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I PCA⧸ICA I 2022 I Lecture 15.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I PCA⧸ICA I 2022 I Lecture 15.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I PCA⧸ICA I 2022 I Lecture 15.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I PCA⧸ICA I 2022 I Lecture 15.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I PCA⧸ICA I 2022 I Lecture 15.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I PCA⧸ICA I 2022 I Lecture 15.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I PCA⧸ICA I 2022 I Lecture 15.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=6N3OAWIsUOU\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=6N3OAWIsUOU\n",
            "[youtube] 6N3OAWIsUOU: Downloading webpage\n",
            "[youtube] 6N3OAWIsUOU: Downloading ios player API JSON\n",
            "[youtube] 6N3OAWIsUOU: Downloading android player API JSON\n",
            "[youtube] 6N3OAWIsUOU: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] 6N3OAWIsUOU: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = Ib9XyxEoxybpMEarwkL ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] 6N3OAWIsUOU: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = 6T9Qg707uR7HaloGbl2 ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] 6N3OAWIsUOU: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] 6N3OAWIsUOU: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr3---sn-q4fzenee.googlevideo.com/videoplayback?expire=1721323163&ei=O_qYZsSuEqu4sfIPtPKnuAs&ip=34.125.104.111&id=o-ADGswvsIgiqlT9N2fflEda0yMrRZqdURVvqfYX8UQ6em&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=_t&mm=31%2C29&mn=sn-q4fzenee%2Csn-q4fl6nsy&ms=au%2Crdu&mv=m&mvi=3&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=80638716&dur=4982.607&lmt=1684533578160268&mt=1721301170&fvip=2&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRgIhAKJmEIwWWB91D2Ufbo-q8twLf6C7sffqIARTGLWCGwwNAiEA2q-y6ZbIelrEckceofWoKYzWgi8hSr9hOHQqNMl7TKE%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRQIgct0aASxjZRvqm8NShYE8qgL9lFy1NBzvKi5MizXW9MUCIQCiSqGsAPJxKiKmDB9dZcv30X638FtFUU5o1lqc0tHM-A%3D%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Self-supervised learning I 2022 I Lecture 16.m4a\n",
            "[download] 100% of   76.90MiB in 00:00:02 at 35.33MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Self-supervised learning I 2022 I Lecture 16.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Self-supervised learning I 2022 I Lecture 16.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Self-supervised learning I 2022 I Lecture 16.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Self-supervised learning I 2022 I Lecture 16.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Self-supervised learning I 2022 I Lecture 16.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Self-supervised learning I 2022 I Lecture 16.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Self-supervised learning I 2022 I Lecture 16.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Self-supervised learning I 2022 I Lecture 16.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=6ZYx_1NlYbI\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=6ZYx_1NlYbI\n",
            "[youtube] 6ZYx_1NlYbI: Downloading webpage\n",
            "[youtube] 6ZYx_1NlYbI: Downloading ios player API JSON\n",
            "[youtube] 6ZYx_1NlYbI: Downloading android player API JSON\n",
            "[youtube] 6ZYx_1NlYbI: Downloading player d60b0ef9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] 6ZYx_1NlYbI: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = ij7Lfy8qZo5r2AVm ; player = https://www.youtube.com/s/player/d60b0ef9/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] 6ZYx_1NlYbI: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = 3cbyHFK6IE_JP841 ; player = https://www.youtube.com/s/player/d60b0ef9/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] 6ZYx_1NlYbI: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] 6ZYx_1NlYbI: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr4---sn-q4fl6nd6.googlevideo.com/videoplayback?expire=1721323247&ei=j_qYZpnXHIrOsfIPsrmCkAs&ip=34.125.104.111&id=o-APUfd7mvzzkyggoONn0myjzI1OmviSFZFHH6t2cLISjx&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=Zb&mm=31%2C29&mn=sn-q4fl6nd6%2Csn-q4flrn7r&ms=au%2Crdu&mv=m&mvi=4&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=88086468&dur=5442.803&lmt=1684533600274167&mt=1721301170&fvip=2&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIgFeCdiNZclhB1c20PyvC6ie_u7fFLGAuRfTZcLP5oSXICIQCuTSIaUYOgdcSTiRicW94tBfr_1X7DT4o61ZLxOU8z5Q%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRAIgO4WSOHXaWRi8v1oPgaKOy-hdnIkOk8YQ34ogr-a4QTwCIAEmKiChb_DaGCne1_ZPCVJZ1wPbgdlvhCpZ5NcHBb6b\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 I Basic concepts in RL, Value iteration, Policy iteration I 2022 I Lecture 17.m4a\n",
            "[download] 100% of   84.01MiB in 00:00:02 at 34.79MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 I Basic concepts in RL, Value iteration, Policy iteration I 2022 I Lecture 17.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 I Basic concepts in RL, Value iteration, Policy iteration I 2022 I Lecture 17.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 I Basic concepts in RL, Value iteration, Policy iteration I 2022 I Lecture 17.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 I Basic concepts in RL, Value iteration, Policy iteration I 2022 I Lecture 17.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 I Basic concepts in RL, Value iteration, Policy iteration I 2022 I Lecture 17.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 I Basic concepts in RL, Value iteration, Policy iteration I 2022 I Lecture 17.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 I Basic concepts in RL, Value iteration, Policy iteration I 2022 I Lecture 17.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 I Basic concepts in RL, Value iteration, Policy iteration I 2022 I Lecture 17.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=UyPn-QR8A7I\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=UyPn-QR8A7I\n",
            "[youtube] UyPn-QR8A7I: Downloading webpage\n",
            "[youtube] UyPn-QR8A7I: Downloading ios player API JSON\n",
            "[youtube] UyPn-QR8A7I: Downloading android player API JSON\n",
            "[youtube] UyPn-QR8A7I: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] UyPn-QR8A7I: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = goMC_Od0FFF7T9AHSVf ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] UyPn-QR8A7I: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = Cr5V8p-eMYocrM9cit0 ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] UyPn-QR8A7I: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] UyPn-QR8A7I: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr1---sn-q4fl6ndl.googlevideo.com/videoplayback?expire=1721323341&ei=7fqYZqGIEbL4sfIPgfWJ6AE&ip=34.125.104.111&id=o-AK923EslmUa7MNTfpQBABT3St2PUYtb1G7CztBXgR1MF&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=O9&mm=31%2C29&mn=sn-q4fl6ndl%2Csn-q4flrner&ms=au%2Crdu&mv=m&mvi=1&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=58113475&dur=3590.780&lmt=1692384013976222&mt=1721301412&fvip=5&keepalive=yes&c=IOS&txp=5318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRQIgDbeSNYPQkAX4RaaOFD0NWgpdxDyj6fAIsvDxNkO5_RkCIQD8LaWa9eiUpgVbUCbpEj1ry-QaKrgfrxhsbEyAYQoucA%3D%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRAIgI7p-WGLKB_ioDlt5CNiMbejG5q62lVUFGncGG8PZjQoCICsKZkx7m5-KMw32TeKlYMqNn10ch0jmsUuG2hlFSY0p\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 I Societal impact of ML (Guest lecture by Prof. James Zou) I 2022 I Lecture 18.m4a\n",
            "[download] 100% of   55.42MiB in 00:00:01 at 35.00MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 I Societal impact of ML (Guest lecture by Prof. James Zou) I 2022 I Lecture 18.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 I Societal impact of ML (Guest lecture by Prof. James Zou) I 2022 I Lecture 18.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 I Societal impact of ML (Guest lecture by Prof. James Zou) I 2022 I Lecture 18.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 I Societal impact of ML (Guest lecture by Prof. James Zou) I 2022 I Lecture 18.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 I Societal impact of ML (Guest lecture by Prof. James Zou) I 2022 I Lecture 18.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 I Societal impact of ML (Guest lecture by Prof. James Zou) I 2022 I Lecture 18.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 I Societal impact of ML (Guest lecture by Prof. James Zou) I 2022 I Lecture 18.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 I Societal impact of ML (Guest lecture by Prof. James Zou) I 2022 I Lecture 18.m4a (pass -k to keep)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Encodings: locale UTF-8, fs utf-8, pref UTF-8, out UTF-8 (No ANSI), error UTF-8 (No ANSI), screen UTF-8 (No ANSI)\n",
            "[debug] yt-dlp version stable@2024.04.09 from yt-dlp/yt-dlp [ff0779267] (pip) API\n",
            "[debug] params: {'format': 'bestaudio/best', 'postprocessors': [{'key': 'FFmpegExtractAudio', 'preferredcodec': 'mp3', 'preferredquality': '192'}], 'outtmpl': {'default': 'files/audio/lectures/%(title)s.%(ext)s', 'chapter': '%(title)s - %(section_number)03d %(section_title)s [%(id)s].%(ext)s'}, 'verbose': True, 'continuedl': False, 'compat_opts': set(), 'http_headers': {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/94.0.4606.85 Safari/537.36', 'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8', 'Accept-Language': 'en-us,en;q=0.5', 'Sec-Fetch-Mode': 'navigate'}, 'forceprint': {}, 'print_to_file': {}}\n",
            "[debug] Python 3.10.12 (CPython x86_64 64bit) - Linux-6.1.85+-x86_64-with-glibc2.35 (OpenSSL 3.0.2 15 Mar 2022, glibc 2.35)\n",
            "[debug] exe versions: ffmpeg 4.4.2 (setts), ffprobe 4.4.2\n",
            "[debug] Optional libraries: Cryptodome-3.20.0, brotli-1.1.0, certifi-2024.07.04, mutagen-1.47.0, requests-2.31.0, secretstorage-3.3.1, sqlite3-3.37.2, urllib3-2.0.7, websockets-12.0\n",
            "[debug] Proxy map: {'colab_language_server': '/usr/colab/bin/language_service'}\n",
            "[debug] Request Handlers: urllib, requests, websockets\n",
            "[debug] Loaded 1810 extractors\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video downloaded successfully.\n",
            "Downloading video from https://www.youtube.com/watch?v=gPCd0xx_OYI\n",
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=gPCd0xx_OYI\n",
            "[youtube] gPCd0xx_OYI: Downloading webpage\n",
            "[youtube] gPCd0xx_OYI: Downloading ios player API JSON\n",
            "[youtube] gPCd0xx_OYI: Downloading android player API JSON\n",
            "[youtube] gPCd0xx_OYI: Downloading player 8eff86d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING: [youtube] gPCd0xx_OYI: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = -VV-WKktqfSqcE9DXcY ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n",
            "[debug] [youtube] Unable to extract nsig function code (caused by RegexNotFoundError('Unable to extract Initial JS player n function name; please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U')); please report this issue on  https://github.com/yt-dlp/yt-dlp/issues?q= , filling out the appropriate issue template. Confirm you are on the latest version using  yt-dlp -U\n",
            "WARNING: [youtube] gPCd0xx_OYI: nsig extraction failed: You may experience throttling for some formats\n",
            "         n = 8jMzZDAsR6JDkAHEpxT ; player = https://www.youtube.com/s/player/8eff86d5/player_ias.vflset/en_US/base.js\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[youtube] gPCd0xx_OYI: Downloading m3u8 information\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Sort order given by extractor: quality, res, fps, hdr:12, source, vcodec:vp9.2, channels, acodec, lang, proto\n",
            "[debug] Formats sorted by: hasvid, ie_pref, quality, res, fps, hdr:12(7), source, vcodec:vp9.2(10), channels, acodec, lang, proto, size, br, asr, vext, aext, hasaud, id\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[info] gPCd0xx_OYI: Downloading 1 format(s): 140\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] Invoking http downloader on \"https://rr5---sn-q4flrner.googlevideo.com/videoplayback?expire=1721323404&ei=K_uYZv7JO7-1sfIP69iSoAc&ip=34.125.104.111&id=o-ADlbSjVSyXNYl-G5ONmRJlr6YBVDP69S6UBzXJ_WvboB&itag=140&source=youtube&requiressl=yes&xpc=EgVo2aDSNQ%3D%3D&mh=_u&mm=31%2C26&mn=sn-q4flrner%2Csn-a5mekn6k&ms=au%2Conr&mv=m&mvi=5&pl=20&vprv=1&svpuc=1&mime=audio%2Fmp4&rqh=1&gir=yes&clen=78028387&dur=4821.321&lmt=1684533820273772&mt=1721301412&fvip=1&keepalive=yes&c=IOS&txp=6318224&sparams=expire%2Cei%2Cip%2Cid%2Citag%2Csource%2Crequiressl%2Cxpc%2Cvprv%2Csvpuc%2Cmime%2Crqh%2Cgir%2Cclen%2Cdur%2Clmt&sig=AJfQdSswRgIhAKOKiqmpi_v9Y5R8-m6VJn3FC3SLRrq1iVRc9VaFfBAIAiEAqiQ9NLHAlEMUY5nlsdQSQjS03ddkrZeH-DyVU9Ey-BQ%3D&lsparams=mh%2Cmm%2Cmn%2Cms%2Cmv%2Cmvi%2Cpl&lsig=AHlkHjAwRQIgOovchsBm2_HwmFWMV5_UwX2cHYzm0dvEzrOy-zuQsowCIQDTIyN3Tr33jRIqS5NoOl0S3hFq-OujOVza0VI5F001jQ%3D%3D\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[download] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Model-based RL, Value function approximator I 2022 I Lecture 20.m4a\n",
            "[download] 100% of   74.41MiB in 00:00:03 at 24.40MiB/s  \n",
            "[FixupM4a] Correcting container of \"files/audio/lectures/Stanford CS229 Machine Learning I Model-based RL, Value function approximator I 2022 I Lecture 20.m4a\"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Model-based RL, Value function approximator I 2022 I Lecture 20.m4a' -map 0 -dn -ignore_unknown -c copy -f mp4 -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Model-based RL, Value function approximator I 2022 I Lecture 20.temp.m4a'\n",
            "[debug] ffmpeg command line: ffprobe -show_streams 'file:files/audio/lectures/Stanford CS229 Machine Learning I Model-based RL, Value function approximator I 2022 I Lecture 20.m4a'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ExtractAudio] Destination: files/audio/lectures/Stanford CS229 Machine Learning I Model-based RL, Value function approximator I 2022 I Lecture 20.mp3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[debug] ffmpeg command line: ffmpeg -y -loglevel repeat+info -i 'file:files/audio/lectures/Stanford CS229 Machine Learning I Model-based RL, Value function approximator I 2022 I Lecture 20.m4a' -vn -acodec libmp3lame -b:a 192.0k -movflags +faststart 'file:files/audio/lectures/Stanford CS229 Machine Learning I Model-based RL, Value function approximator I 2022 I Lecture 20.mp3'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleting original file files/audio/lectures/Stanford CS229 Machine Learning I Model-based RL, Value function approximator I 2022 I Lecture 20.m4a (pass -k to keep)\n",
            "Video downloaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JupjFnfmrxkL"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "from pydub import AudioSegment\n",
        "from pydub.utils import make_chunks\n",
        "import openai\n",
        "\n",
        "# Define the directory containing the audio files\n",
        "input_dir = \"files/audio/lectures\"\n",
        "output_dir = \"files/transcripts/lectures\"\n",
        "\n",
        "# Ensure the output directory exists\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Get all mp3 files in the input directory\n",
        "audio_files = glob.glob(os.path.join(input_dir, \"*.mp3\"))\n",
        "\n",
        "# Check if any audio files are found\n",
        "if not audio_files:\n",
        "    print(f\"No audio files found in directory: {input_dir}\")\n",
        "else:\n",
        "    print(f\"Found {len(audio_files)} audio files in directory: {input_dir}\")\n",
        "\n",
        "# Function to split audio into chunks\n",
        "def split_audio(audio_filename, chunk_length_ms=10 * 60 * 1000):  # 10 minutes\n",
        "    print(f\"Splitting {audio_filename} into chunks of {chunk_length_ms / 60000} minutes each.\")\n",
        "    audio = AudioSegment.from_file(audio_filename, format=\"mp3\")\n",
        "    chunks = make_chunks(audio, chunk_length_ms)\n",
        "    chunk_filenames = []\n",
        "    for i, chunk in enumerate(chunks):\n",
        "        chunk_filename = f\"{os.path.splitext(audio_filename)[0]}_part{i}.mp3\"\n",
        "        chunk.export(chunk_filename, format=\"mp3\")\n",
        "        chunk_filenames.append(chunk_filename)\n",
        "        print(f\"Created chunk: {chunk_filename}\")\n",
        "    return chunk_filenames\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F8VkfRqKF1Sh",
        "outputId": "54f96ab9-6477-473e-85a0-04f42fd81035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 19 audio files in directory: files/audio/lectures\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import whisper"
      ],
      "metadata": {
        "id": "eubVFTTknXCk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if 'load_model' is available\n",
        "if hasattr(whisper, 'load_model'):\n",
        "    model = whisper.load_model(\"base\")\n",
        "    print(\"Whisper model loaded successfully.\")\n",
        "else:\n",
        "    print(\"Error: 'load_model' function not found in the 'whisper' module. Please check your installation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tk1emcuzqBWu",
        "outputId": "d7fe945d-7422-4b1a-d8c8-7b3ae3e21487"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 60.5MiB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Whisper model loaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"base\")\n",
        "\n",
        "for audio_filename in audio_files:\n",
        "    try:\n",
        "        print(f\"Selected audio file: {audio_filename}\")\n",
        "\n",
        "        output_file = os.path.join(output_dir, f\"{os.path.basename(audio_filename)}.txt\")\n",
        "\n",
        "        print(\"Converting audio to text...\")\n",
        "\n",
        "        if os.path.getsize(audio_filename) > 26214400:\n",
        "            print(\"Splitting audio file into smaller chunks...\")\n",
        "            chunk_filenames = split_audio(audio_filename)\n",
        "            transcript = \"\"  # Initialize an empty transcript\n",
        "            for chunk_filename in chunk_filenames:\n",
        "                print(f\"Transcribing chunk: {chunk_filename}\")\n",
        "                audio = whisper.load_audio(chunk_filename)\n",
        "                result = model.transcribe(audio)\n",
        "                transcript += result[\"text\"] + \"\\n\"\n",
        "        else:\n",
        "            audio = whisper.load_audio(audio_filename)\n",
        "            result = model.transcribe(audio)\n",
        "            transcript = result[\"text\"]\n",
        "\n",
        "        os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
        "\n",
        "        with open(output_file, \"w\") as f:\n",
        "            f.write(transcript)\n",
        "\n",
        "        print(f\"Transcript saved to {output_file}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"An error occurred while processing {audio_filename}: {e}\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "y_sxvsY3GfOM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "directory = '/content/files/transcripts/lectures'\n",
        "\n",
        "if os.path.exists(directory):\n",
        "    print(\"Directory exists!\")\n",
        "else:\n",
        "    print(\"Directory does not exist. Please check the path.\")"
      ],
      "metadata": {
        "id": "JUlmIoGYH49f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(directory):\n",
        "    num_files = len([f for f in os.listdir(directory) if os.path.isfile(os.path.join(directory, f))])\n",
        "    print(f\"Number of files in '{directory}': {num_files}\")\n",
        "else:\n",
        "    print(f\"Directory '{directory}' does not exist. Please check the path.\")"
      ],
      "metadata": {
        "id": "kq11obOaIIDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "video_id_mapping = {\n",
        "    \"Stanford CS229 Machine Learning I Introduction I 2022 I Lecture 1.mp3.txt\": \"https://www.youtube.com/watch?v=Bl4Feh_Mjvo\",\n",
        "    \"Stanford CS229 Machine Learning I Supervised learning setup, LMS I 2022 I Lecture 2.mp3.txt\" : \"https://www.youtube.com/watch?v=gqKaVgQxEJ0\",\n",
        "    \"Stanford CS229 I Weighted Least Squares, Logistic regression, Newton's Method I 2022 I Lecture 3.mp3.txt\": \"https://www.youtube.com/watch?v=k_pDh_68K6c\",\n",
        "    \"Stanford CS229 Machine Learning I Exponential family, Generalized Linear Models I 2022 I Lecture 4.mp3.txt\": \"https://www.youtube.com/watch?v=goDDnBbJQ4g\",\n",
        "    \"Stanford CS229 Machine Learning I Gaussian discriminant analysis, Naive Bayes I 2022 I Lecture 5.mp3.txt\": \"https://www.youtube.com/watch?v=RMy_1mO4HLk\",\n",
        "    \"Stanford CS229 Machine Learning I Naive Bayes, Laplace Smoothing I 2022 I Lecture 6.mp3.txt\": \"https://www.youtube.com/watch?v=ADj95edZc0w\",\n",
        "    \"Stanford CS229 Machine Learning I Support Vector Machines I 2022 I Lecture 7.mp3.txt\": \"https://www.youtube.com/watch?v=dzDOqrac9Ks\",\n",
        "    \"Stanford CS229 Machine Learning I Neural Networks 1 I 2022 I Lecture 8.mp3.txt\": \"https://www.youtube.com/watch?v=ZMxfDWPXmjc\",\n",
        "    \"Stanford CS229 Machine Learning I Neural Networks 2 (backprop) I 2022 I Lecture 9.mp3.txt\": \"https://www.youtube.com/watch?v=UbtTv7j1tzU\",\n",
        "    \"Stanford CS229 Machine Learning I Bias - Variance, Regularization I 2022 I Lecture 10.mp3.txt\": \"https://www.youtube.com/watch?v=7AQYw5FOVcw\",\n",
        "    \"Stanford CS229 Machine Learning I Feature ⧸ Model selection, ML Advice I 2022 I Lecture 11.mp3.txt\": \"https://www.youtube.com/watch?v=NirZnqwYfYU\",\n",
        "    \"Stanford CS229 I K-Means, GMM (non EM), Expectation Maximization I 2022 I Lecture 12.mp3.txt\": \"https://www.youtube.com/watch?v=LMZZPneTcP4\",\n",
        "    \"Stanford CS229 Machine Learning I GMM (EM) I 2022 I Lecture 13.mp3.txt\": \"https://www.youtube.com/watch?v=khTGx7m3Y8A\",\n",
        "    \"Stanford CS229 Machine Learning I Factor Analysis⧸PCA I 2022 I Lecture 14.mp3.txt\":  \"https://www.youtube.com/watch?v=o2KzJdbOwMc\",\n",
        "    \"Stanford CS229 Machine Learning I Latent Semantic Analysis (LSA) I 2022 I Lecture 15.mp3.txt\": \"https://www.youtube.com/watch?v=FVLZG_oHUIw\",\n",
        "    \"Stanford CS229 Machine Learning I Self-supervised learning I 2022 I Lecture 16.mp3.txt\": \"https://www.youtube.com/watch?v=6N3OAWIsUOU\",\n",
        "    \"Stanford CS229 I Basic concepts in RL, Value iteration, Policy iteration I 2022 I Lecture 17.mp3.txt\": \"https://www.youtube.com/watch?v=6ZYx_1NlYbI\",\n",
        "    \"Stanford CS229 I Societal impact of ML (Guest lecture by Prof. James Zou) I 2022 I Lecture 18.mp3.txt\": \"https://www.youtube.com/watch?v=UyPn-QR8A7I\",\n",
        "    \"Stanford CS229 Machine Learning I Model-based RL, Value function approximator I 2022 I Lecture 20.mp3.txt\": \"https://www.youtube.com/watch?v=gPCd0xx_OYI\"\n",
        "}"
      ],
      "metadata": {
        "id": "T3jCTB_1b9C5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "transcript_dir = '/content/files/transcripts/lectures'\n",
        "\n",
        "data = []\n",
        "\n",
        "for i, filename in enumerate(os.listdir(transcript_dir)):\n",
        "    if filename.endswith(\".txt\"):\n",
        "        # Get the corresponding YouTube URL from the mapping dictionary\n",
        "        youtube_url = video_id_mapping.get(filename)\n",
        "\n",
        "        if youtube_url:\n",
        "            # Construct the title by replacing underscores with spaces and formatting it properly\n",
        "            title = filename.replace('_', ' ').replace('.Mp3.Txt', '').title()\n",
        "\n",
        "            # Read the transcript\n",
        "            with open(os.path.join(transcript_dir, filename), 'r') as f:\n",
        "                transcript = f.read()\n",
        "\n",
        "            # Create a dictionary for the video and append it to the data list\n",
        "            video_data = {\n",
        "                'id': i,\n",
        "                'url': youtube_url,\n",
        "                'title': title,\n",
        "                'transcript': transcript\n",
        "            }\n",
        "            data.append(video_data)"
      ],
      "metadata": {
        "id": "EXuBHPnImYK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "c98ufDOJIuMI",
        "outputId": "6e7a7c67-d97f-498f-e86f-01f7286fb619"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 1,\n",
              " 'url': 'https://www.youtube.com/watch?v=ZMxfDWPXmjc',\n",
              " 'title': 'Stanford Cs229 Machine Learning I Neural Networks 1 I 2022 I Lecture 8.Mp3.Txt',\n",
              " 'transcript': \" Hello everybody. Hi. My name is Masha. Some of you may have met me already as part of office hours and seen me post on Ed and things like that. I'm really excited to be giving lectures today. It's going to be in a slightly different format than ten use or criss-os. So feel free to give me feedback on that afterwards on Ed or by email whatever you like. But the topic today is actually kind of fun. So we're going to start for a little bit into deep learning, so neural networks. I'm assuming everyone here has heard of neural networks before. Anyone who hasn't? Yeah, that's what I thought pretty much. So it'll be fun to see how the ideas of what's happening in the state of the art actually come back to all the things we've been talking about so far. So ideas and linear regression, ideas and logistic regression, all of this will connect to how neural networks work. So before I get into the mathy notation type of material, I wanted to start with some motivation. Who here has heard of GPT-3? Yeah, a lot of you. So it made big waves a couple years ago. It was a huge, huge model, but it was able to do really impressive things. Like, in this case, here it came up with a poem on its own, right? And the hope is that these deep learning models learn to be so expressive that they can do creative things like creative writing. More recently, this was very, very recent. Has anyone heard of Dali too? A few of you, yes. So this is very, very recent. And so Dali too is able to generate images. And the prompt here is an astronaut writing a horse as a pencil drawing. And you can see the main one that I picked out and then a bunch of different versions of what also can come up with. So deep learning is very, very powerful for better or worse. But it also has so much potential to do such amazing things, right? Obviously, this is cool, but there's also applications in medicine, applications and education, applications in things like autonomous driving, which could hopefully make a road safer. So there's lots of potential here. And that's sort of the backdrop to where we're going to start. We're going to talk about the origin story of all these things. So we're going to start with supervised learning with nonlinear models. So so far, most of what we talked about has been linear models. And now we're getting into the nonlinear territory. And I'll talk a little bit about what that means. And then we'll get started with neural networks. We'll figure out what the heck they are. How we can define them and netlet next lecture will actually talk about how you can optimize them. And I believe Tangu will be giving that lecture. Any questions before I get started? Cool. All right. So first, let's think about linear regression. So we've seen this a bunch. And so we can get started with a data set that we might have, right? So we might have some x-s and y-s. So some inputs and outputs in our data set. And say our data set is of size n, right? And we know for linear regression that we have a prediction that we can make according to something like this. Right? So we have a linear function that we're using to predict. And this function depends on our inputs x. Can anyone help me out with what our cost function might look like in terms of y's and h's for linear regression? Okay. h minus y. Okay. I heard somewhere. Some of our i. Yeah. This looks good to me. This looks good to everyone. Familiar? Hopefully we've seen this all before. Awesome. Okay. So we have a prediction here. And we have our label. And what we can do is we can also write this directly in terms of our parameters. Our parameters here are theta and b. Cool. I just plugged it in. Makes sense so far, right? And what we can do is run things like gradient descent or stochastic gradient descent in order to optimize this. Cool? So last lecture, you talked about a slightly different set of models. You talked about kernel models. And so with kernel models, we still have a similar set up, right? So we have our x-eyes, our y-eyes, right? And then what does our h-theta of x look like? So what does our prediction look like with kernel models? Is there anyone remember from last class? It's very similar to what we had before. Yeah. And what's 5x? Sorry? The feature map. The feature map. Exactly. So what's interesting about this set up is we're still linear in parameters. But we're non-linear in the inputs. Because 5x can be any non-linear function that you discussed last time. So what if we want to be non-linear in both the parameters and in the inputs? So generally speaking, what if we want to do something like this? So our h-theta of x is anything non-linear. So let's say theta 1 cubed x2 plus maybe square root in there. Theta 5x4, maybe square root the whole thing, right? So this type of model could be a lot more expressive potentially, right? But we also want to think about how can we make this computationally tractable? How can we make this useful? Okay. So we have some non-linear model. And by the way, all these notes will be up online afterwards. So if you don't finish writing something, please don't worry about it. It will be up. And if you want to follow along, I should have mentioned this earlier, but there is a template up as well. So it's going to be what I'm writing on, so the blank version. Cool. So let's go back to our non-linear model now. We can assume that our x-i's are in our d. So some vector of features or inputs. And our yi is some scalar, so just an r, right? This is pretty standard. We've been looking at this type of formulation a whole bunch. And then our h theta is a mapping from our d, which is our inputs, to r, which is the dimensionality of our outputs. So the cost function we're going to think about here for our now non-linear model is going to look very familiar. So...\\n But for one example, i, we're going to have j i of theta is equal to the square of the difference between the class label and the prediction. So y i minus h theta of x i and all of that squared. So that's the cost for one example. If we want to get the cost for the whole entire data set, we're going to average. So what this is going to look like is we're going to have j of theta, 1 over n, n is the size of our data set from i equals 1 to n. And then here we have j i of theta. So this is for entire data set. Okay. So this constant is a little different from before. This is a common convention in deep learning. It's usually the, this is called the mean squared error. So it's usually the average. The constant really doesn't matter. Your optimizer is going to be the same regardless of what constant you're going to have out front of that sum. So that makes sense. All right. So now we're going to talk about how do we, oh, yep, question. So n is the size of your data set. So you're just, this is the mean squared error. So you're averaging over all the squared errors in your data set. So the reason the constant doesn't matter is when you take the gradient, your x that's going to result in your minimum is going to be the same regardless of whether it's one over n or one over two. You asked why do we use it at all? Sometimes it's helpful for scaling. But other than that, there's no real magic behind this. It's just a convenient thing to do. It makes sense to average over your errors. Yeah, it's a nice way to scale things. Thank you. No problem. Cool. So what we want to do, once we have this cost function, is we want to minimize it. One way to do that, we can use gradient descent. And so this notation here, we're assigning, it's kind of like coding notation, you can think of, we're assigning the right side to the left side. Okay. Can anyone tell me why this is gradient descent? What is written here and not like stochastic gradient descent? What makes it gradient descent? Yeah. Reason the whole data set. Uh-huh, yeah, exactly. So you're considering the whole data set here. And the reason for that is, if we write out what's actually going on here, rj of theta is so that 1 over n is here. And we have i equals 1 to n over j i. Sorry, j i, that's data. Right, so we're reasoning over the whole data set. So each update here considers the entire data set that we have. Cool. All right. So here's stochastic gradient descent. So the idea here is we're considering now only one single example. Every time we update theta. Right, so we have some hyperparameter alpha. Um, alpha same as for gradient descent. Number greater than zero. And we're basically initializing our parameters theta randomly at the start. And then we go through some number of iterations. We sample some example from our data set. And we do this with replacement. And we continue on until either we converge to something we're happy with or we reach our n itter maximum number of iterations. So this is with replacement. I'm going to briefly sketch out what SGD usually looks like more commonly in deep learning settings, just so you guys have an idea. So this is one variant. Here is going to be another one. And so the variant that's an algorithm one that's going to be in your notes. This other one is not, but I just think it's helpful to know some of the terminology when you go into the for a deep learning as well. Okay. So we go through a for loop where, um, let's say we're indexing it K. We have one tip and epoch. So epoch is basically a term to mean you've gone through your entire data set. And so in deep learning you'll often see or if you read deep learning papers, you'll see, oh, we trained for a lot number of epochs. That's what that means. That's how many times the optimization is basically gone through the data set. So for K equals one to an epoch, we can shuffle the data. And then for J from one to an eater, here we might not have enough time or desire to go through the entire data set. So maybe we decide that we want to go through 500 examples out of the data set and call that an epoch. That's also fine. So we have for J equals one to an eater. We're doing the same type of update. And here we have no replacement in this inner for loop with the J index because we don't want to look at the same example twice in the data set. Does this make sense? Pretty much. And slightly different terminology. Cool. Yeah. Yeah. So basically having this number of epochs, and times 24 for like 24 in itself, if the data hasn't had unsamplified, then I would compare to one to that. But I would compare to one to like endless. The latter. So the question is what is an epoch mean? And basically it's if you go through the entire data set. It's how many times you go through the entire data set. Any other questions here? Cool. I'll talk about the last version of gradient descent for today. And this is mini batch gradient descent. So with mini batch gradient descent, the main difference is you're considering B or a batch number of gradients at a time. The reason we want to do this is with things like GPUs and parallelism, this actually speeds up computation. So we can compute B gradients at the same time or simultaneously as opposed to doing them sequentially. And that can be quite a bit faster. Let me write out some of that. So we're computing B gradients. And they look like maybe grad J, J1 of theta all the way to grad Jb of theta. And we do this simultaneously.\\n So one question you might be thinking about how do you choose B? And very often you choose B empirically. So you test things out, you look at your validation set, things like that. And you'll talk about evaluation a bit later as well. But one way to choose B is choose the maximum B that your GPU memory can handle. And that's sort of a good way to speed up what you're doing. But the trade-off is usually, and this might come up in your homework as well, usually the lower the B, the better the performance of the algorithm. And I'm not going to talk too much about why this is the case. This is also active research. But just to give you some idea of how folks go about choosing these numbers. Any questions about many batch gradient descent? Yeah. I guess this is exactly the same as all of you, the syntax, and you're just doing this. I think a little batch is a whole school of the whole thing. Yes, yes, precisely. Any other questions? Yeah. Any other questions about the gradient replacement? Yeah. That's not exactly what does the gradient replacement mean. Yeah, so with replacement means say we picked example two, we can pick example two again in the future. Whereas without replacement in the corner case, it means if we picked example two within that j for loop, we will not pick example two again until we get to the next epoch. You're just randomly choosing one example. It can happen to be the same example. It cannot. So in the middle one, you randomly pick examples until you reach an error. Whereas in the left one, you're more trying to go through your entire data set and then do that again. Any other questions? On anything gradient descent related? Yeah. So where are the mini batch case? I'll be actually to not fierce no matter what was replaced. So with the mini batch, no, because you're considering say say your batch sizes 10 or 64 or whatever. You don't want multiple examples and that to be the same. You want all the examples to be different. Between batches, do we replace these elements back to those that? You can. Sometimes you don't. Sometimes you do. It's sort of like a design choice, but you can. In this case, when it's saying without replacement, it means that within one batch, you don't have doubles. Thank you. Yeah, no worries. Other questions? Okay. All right. Next, we're actually going to define some neural networks. So we talked a little bit about how we optimize these things, but we didn't really get into, for example, well, how do we define the neural network yet? Or how do we compute the gradients? Right? Like when we talk about multiple gradients, how do we actually compute these things? And we need to be able to do this in a way that's computationally efficient. And progress in machine learning really took off in the last, you know, 10, 20 years, because of advancements in hardware, because we're able to paralyze on GPUs and make these things so much faster, and also algorithmic developments as well, of course. Cool. So we're going to talk about neural networks today and how we define them. The back propagation, which is how do we compute these gradients? That will be covered next lecture. Okay. So this example came up at the very start, I think maybe first lecture or something like that. But the example here, we're looking to predict housing prices. Right? And we looked at how we can do this with linear regression, with linear models. And say with our linear model, given the size of a house, we have some data where we have some, you know, size and prices, and we can plot them on this plot. And our model maybe looks something like this, with something like linear regression. Okay? What's a problem with this? Why might this not work so well? Any thoughts? Yeah. Yeah. Yeah. Yeah. That's a good first one. So prediction might have a non-linear relationship with the input, right? And we only have a linear model. Maybe that model doesn't capture the relationship that well. What's another reason this is not great? So repeat that. Yes. Yes. Yes. Exactly. The second issue with this is that prices can't be negative. And when we have a linear model, like we do, they can. Right? Nothing's preventing them from being negative. Do you want to think of like the simplest thing you can do to fix this problem? Yeah. Sorry. Say that. You don't face the intercept to be zero. Yes. You can fix the intercept to be zero. So what does that mean for negative numbers? So fixing the intercept to be zero would be this, right? Yeah. Yeah. So what else would stand for price? We'll have negative size. But also doesn't make sense. Yeah. So one thing we can do. Let me write out these issues first, but I'll show you a solution in just a second. Does anyone know a function that can fix this for us? Sorry. Say that, louder. Okay. Any other ones? Yeah. Relies. Does anyone heard of relies? I'm gonna talk about relies in just a second. Okay. So the issues that we talked about here are the prediction might have a nonlinear relationship. With the input. And the second issue is we can have negative braces. Okay. So our, what we want our relue to look like, or what we want this function to look like, is something like this. So basically for all things that are in the negative side, we map to zero. So that's what our relue is going to be. And what that looks like in math terms, we have our regular prediction. But we want the maximum between what linear regression would output as a prediction and zero. And then our parameters here are going to be w and b. So this is relue. This is how it's usually written. And this is the notation that we will use. So you can say that relues a function of t here. And then really we can just write our prediction as this relue function. Which is wx plus b. And so anyone knows.\\n know what ReLU is, what it's called in deep learning terms. Yes? X, X, Y, Y, Y, Y. Yes. Any other, so like what category of functions does it in deep learning? Yeah. Exactly. Activation function. So our ReLU is an activation function. And I can't even tell me is ReLU linear? Okay, raise hands if you think it's linear. Okay, nonlinear? Yeah. Yeah. It is definitely nonlinear. The maximum rates are nonlinearity there. Okay. So this is our nonlinearity in deep learning or often is. It's also sometimes called one neuron. Okay. So going back to our housing price prediction setup, yeah, question? The question of our activation function. Yes. Activation functions are by definition nonlinear. So we'll talk at the end a little bit about what happens if they are linear. Other questions? Cool. All right, so let's set up our high dimensional inputs. Example. Right, so far we've, especially in this plot, we've been looking at one input, one output, so scalar to scalar. So what if we have more features, so high dimensional input? And this is the case when we have x, b, and rd, and y, b, still scalar. So we're still predicting housing prices, for example. So our new terminology for our prediction is value of wTx plus b. Okay. And so our x is just going to be stacked features or inputs, so we have x1 all the way to xd. And this is in rd. And then our weights, our weight vector, w is going to be in what dimension can anyone tell me based off of how I've written it? D, that's right. Because we're making a dot product with x. And then our b is called our bias. And it is going to be scalar. What we want to do in deep learning is we want to stack these neurons. So output of activation functions is going to be the input to the next one. And this is what creates that expressivity of deep learning models. Basically, they have a bunch of non-linearities that are stacked one on top of the other. And this becomes a super flexible framework that can represent a lot of different domains. Okay. So now let's make the housing price prediction problem a little bit more concrete. So let's say our x is going to be in r4. And say besides size, or square footage, which is x1, we're also going to consider things like number of bedrooms in the house. What's another thing? Maybe we can consider the zip code that the house is in. Maybe it's close to a subway or something, right? The last thing we'll consider is maybe something like wealth of the neighborhood. So these are our features or inputs. And what we might want to do is compute some intermediate variables. So what I mean here is maybe there are some things that combine some of these ideas that can help us make a prediction for what the price of the house might be. So one example is maybe the maximum family size that a particular house can accommodate. So what would the maximum family size potentially depend on? Out of the four inputs that we have. Yeah. Size and number of bedrooms. Size and number of bedrooms. Yeah. I would agree with that. So we can also think of other variables like maybe how walkable the neighborhood is. And that might depend on the zip code, for example. And the last one is maybe school quality in the neighborhood that this house is in. And this will be our A3. So A1 through A3 are some intermediate variables that we think might be helpful to make predictions about housing prices. Okay. Well, so how could we maybe write these out in terms of math notation? Well, let's use our values that we just found out about. And do value of some linear combination of the features that we think might make sense in this context. So maximum family size. Maybe we have combo, like someone said, there of the size, which is x1. And then maybe we add the number of bedrooms, which is x2, and we have some bias term. Which is going to be data 3 here. So theta 1, theta 2, theta 3 are all parameters. And then we can do the same thing for the rest of these intermediate variables. So we can say theta 4. So walkability depends on x3, which is zip code. And then we have another bias term. And then finally A3. So we have value of theta 6. So A3 is walkability. Maybe that depends on, or sorry, A3 is school quality. So that depends maybe on zip code, which is x3. And maybe on wealth of the neighborhood, which is x4. And then we have some bias here as well. So these are the intermediate variables that we think might be helpful here. Okay. And the last thing that we might want to do here is, let me just change this notation so it's not confusing for the notes later. These are all W's and the biases are going to be B's. These are B2's, B1's, and make sure. Oh, sorry. Okay. No, I actually had it right the first time. Ignore me. So these were all theta parameters. At the end of the day, it doesn't matter. I just want to make sure that it matches your notes so it's not confusing later. So 1, 2, 3, theta 4, theta 5. Okay. So this is actually one layer that we defined here. Okay. And finally, once we have these intermediate variables, we're actually going to make the output. We're going to construct the output. Right. And our output is our h theta of x, which is going to be, if we follow this construction, we're going to write value of. And here we're going to make combinations, a linear combination of these intermediate variables A. Right. So.\\n We're going to have theta 9, a1 plus theta 10, a2 plus theta 11, a3 plus theta 12. Okay? One thing, so this is going to be our end goal or end prediction here. One thing that usually happens in deep learning is we actually, for the output, we don't use a relu. So it's sort of like convention. Nothing is necessarily stopping you from doing that. It's just by convention, usually we just have a linear layer at the end. Cool. So now that we look at this diagram that's here on your right. So we have all the things that I talked about, right? We have the size, the number of bedrooms, the zip code, the wealth, and it's going into these intermediate variables, right? So this is a1, a2, a3. Okay? And the weights that we're considering that are relating sort of taking from the first set of inputs x to a. So for example, here we have theta 1, here we're going to have theta 2, and so on. Does this make sense? And this structure that we, yep, sorry question. Right now they're all scalar. Everything we're talking about right now is scalar. So whenever we have the subscript, it's usually scalar. Yep. You know, you're having a few intermediate variables at the end. You're just using those intermediate variables. Yes. It's possible that some of those are not available, but still we can support. So is anyway, you can have a transfer, therefore, you work the end of some of these. Yeah, I mean, if you look at a2, for example, if you set the, say this is x3 is positive, and you set theta 4 to 1, and theta 5 to 0, then you transfer over all the information from x3. Okay, but this structure, we came up with the structure based off of our knowledge, right? This was not something that was determined by some algorithm. We just came up with it because it seemed to make sense. So this is called prior knowledge, and infusing your model with it, basically. But what if we want to be a little more general? What if we don't want or don't have the prior knowledge to do this in a way that results in good performance? So this is getting into something called fully connected neural network. And what this means is we no longer think about these ideas of family size, walkability, school quality. We don't know what those intermediate variables might be, but maybe they depend on all of the inputs. So each intermediate variable will depend on every single input. So this is going to get messy, but I'll try to use different colors. So every single variable here will depend on all the ones that came previously. And this is a much more general way of thinking about this. Right? We don't have to infuse this prior knowledge into the system. We can let the neural network figure it out. So what this looks like mathematically is maybe we would have like a one, be equal value of some weight x1 plus some weight x2 plus some weight x3 plus another weight x4 and plus a bias term. And we can do this for a2 and so on and so forth. Does that make sense? Cool. So what this looks like if we start looking at vector notation now more, this might look like this. So we have a1 is equal to the value of w1. This higher index notation in square brackets is going to refer to layers. So this would be the first layer and this would be the second layer in this network. So we have w1 layer 1 transpose with all the inputs x. Now this is a vector. So now we're doing a dot product and we add some bias term. Okay. Can anyone tell me what dimensionality w1 in the first layer is? Yeah. That's right. And that's because our x is dimensionality 4 and our bias is still scalar. Okay. And then we can do the same thing. We can say this still first layer. Okay. And last one. Same thing. Okay. And then finally we have our prediction. And the prediction now is going to use weights from the second layer. And it's going to operate on those intermediate variables a. Okay. So we're going to have w2 and here we have b2. And now w2 is going to be of what dimension? Yeah, I heard it somewhere. Yes. Because a is of dimension 3 here. And the bias still scalar. Okay. So this is a two layer neural network. And this is the same thing as saying we have one hidden layer. So intermediate variables are referred to in deep learning as hidden units and associated layers are hidden layers. Okay. Any questions on that? Yeah. Yes. Great question. Great question. So you're going to be limited by compute. But aside from that, it's a lot of experimentation. So for example, gpt3 has a lot, a lot of layers. But it's also dealing with a lot of data. If you have just a little bit of data and just a few examples, you probably don't want to use a very big model. And I think you'll talk a little bit about why shortly. Any other questions? Yeah. So the hope is that the network learns different representations. But technically nothing is really stopping it from exactly what you said. Just replicating ideas, but it often doesn't. And it's trying to learn these a's in the best way that can help the neural network make a prediction, H theta of X. Right. So this ends up working actually quite well. Yeah. This time when we can add to the network, then we can get errors as they're in inference. Yeah. So that's actually an act of research area as well. It's called interpretability in deep learning and either figuring out if there is any or figuring out how we can induce there to be some level of prior knowledge. So some interpretability. I think there's a question at the back yet. Uh-huh. So what do you think is the weak? Yes. You're going to be applying product. Uh, that you're going to be applying to what? Yes. So W are the weights that are you're going to be applying to the X's and then W. So those are W1 with the square bracket at the top. And then W2 with the square bracket at the top is going to be the weights you're applying to the A's. Yep. All right. Okay. So this is some notation. Yes. Yes. Question.\\n I don't get the sense that if we get rid of the values, everything is just linear. So what's the point of the neural network versus just arriving? Yeah, so that's a great question. You're completely right. If you get rid of the values, things are just going to be linear. The values are what make the neural network be more expressive. So those non-linearities, those activation functions are really the heart of the neural network. Okay, cool. I'm going to move on in the interest of time. So we have a two layer neural network. And we just talked about all these things. The only difference here is that we're changing notation a little bit. So we're introducing the Z, which is just a linear combination of X's with our weights and our biases. And then we still have our A's. The number of A's here is M. So this is the number of hidden units that we're considering. So we had three in the last example. More generally, we'll have M. And then, yeah, that's otherwise this is exactly what we just wrote out before. Does this make sense to everyone? Any questions on this? Okay. So we're going to talk about vectorization. We're going to make this even more vectorized, right? So we had like a lot of notation, a lot of indices here. We want to get rid of as much of that as possible. One, to make things cleaner and not have to write all these indices everywhere. And two, which is the more important reason, vectorization actually makes things faster. It makes things better able to be paralyzed on, for example, GPUs. So what we can do first is think about those weights in our first layer, right? Those W's with the square, square bracket one. And what we can do is we can transpose them. So they're rows and stack them in a matrix. And so what we're looking here at here is M by D. So M is our hidden unit dimension. And D is our input dimension. So these are all the weights in our first layer. And then what we can do is we can actually write out those equations from before in this vectorized form. Where, for example, we can write out z1. If we take the first row of this, z1 will be w1 of 1 transpose x1 plus b11, right? Which is that first row that we had before. Okay? And but this looks way, way nicer. And this is our vectorized notation. Any questions on this? So it's the exact same thing, just more compactly written. Okay. Okay. So now that we have these z's, this is actually called preactivation. So this is before we applied our relus. And we have these z's. This is capital W. I'll do it with those little bars at the top. And it's all our weights from our first layer. We take the x and we add our biases, which are also stuck together. And all of this is going to be of dimension m, which is the same dimension as our hidden units. Now, we want to get a's out of this. And to do so, we need to apply the value to every element in the z vector. So our a's are a1 through a m. And we want to apply a value to each one of these z's. We're actually going to abuse notation here a little bit. And we're just going to write this by definition to be a value of z. So it's an element-wise operation. And we're going to do it the same way as we would for a scalar. And then what we can do is we can write our second layer weights. In the second layer, we only have a scalar output that we want. So we only have one weight vector to include here. That we're going to transpose to be a row. And this is going to be in dimension 1 by m. Any questions on that part? Okay. And we're still going to have our bias in the second layer, which is still a scalar. And so our final output here is going to be this w2 matrix times a dot predicted with a and the bias term. And what I said before is that vectorization helps us parallelize things on GPUs. Okay. So we talked about two layer neural networks. What if we have more layers? So notation just follows. Right? So before we stopped with one hidden layer, which is a two layer neural network. And now we're going to have r minus 1 hidden layers, which is an r-layered neural network. And like I mentioned before, so all the hidden units will have relus, whereas the hidden layers, whereas the prediction just by convention will not. And we'll refer to these big w's as weight matrices. And these bias terms will just be called bias. Nothing really changed. And these a's will be hidden units. One thing to note is the dimensionality of these a's. Right? So what is the dimensionality of a k? So a layer k. And that's going to be, we're going to refer to that as mk. Okay? And so can anyone tell me what the dimensionality is of w layer one? So I say that louder. D cross k. What do folks think? So it's. K cross D. Is that looking? Yes. Yes. Yes. There we go. So it's m1 cross D. So D is our input. So we want this matrix to do matrix multiplication with x. X is of dimension D. So we want that last dimension to be D. The first dimension is the dimension we want as the output. The output will be a1. A1 is of dimension m1. Does that make sense? Okay. And then so just for practice, what would w2 be? Yeah. Would this be our layer network for our minus 1 there? This would be an r layer network with r minus 1 hidden units. What is the dimensionality of w2? And you want to help me? Yes. m2 cross m1. Because the input will be a1. That's what's being multiplied with w2. And the output will be h2. So we want m2 output. Okay. Cool. And so this can more generally we can write this for wk. So m2 is of r mk.\\n cross MK-1. And BK is just going to be MK dimension. Any questions here? No? OK. Awesome. So we got this question earlier. Why do we need an activation function, ReLU? Can anyone remind me why do we need it? Yeah, so it's our non-linearity. It's what makes what we're doing here, non-linear. But for fun, let's see what happens if we don't have the ReLU, at all, or we have it be just identity. This is a one, sorry. OK. So we have our hidden layer A1. And then say we only have one hidden layer. So our output here is going to be W2 of A plus B2. OK? And then if we actually substitute in for A1, what are we going to get? So we're going to have W2 of W1 x plus B. OK? All of that A, oh, sorry. That was A plus B2. And then we can actually expand it out. And we're going to get, watch my math, so I don't mess this up. I'm going to get W2, W1 x plus W2, B1 plus B2. So what does this really look like? Well, we can define these to be, say, this is W tilde. And say this is B tilde. The second term doesn't depend on x at all. And the first term does. OK? So this is just a linear function of x as we would have in linear regression. Essentially, everything would collapse. And we're here linear in these parameters. Any questions about this? So if we lose the value, we lose the nonlinear expressivity of the neural network. Yeah? What's the probability of integration function? What are the probability of? Yeah, you can definitely have other ones. So in the notes, I think we mentioned the sigmoid activation function and the tan H activation function. I would probably say relus the most common, but it really depends on your application, the kinds of outputs you might want, things like that. There are definitely other ones. And there's also B sides just, the kinds of outputs that you might want. These activation functions have certain properties when you try to compute gradients with them and things like that. And that's a little bit beyond the scope of this lecture. But if you have questions about this later come by. And then I'll be happy to chat. Any other questions on this? Yep. On back, it will be very easy. The advantage of that is that it's the closest to what we can call them the linear activation function. Yes. So why is the line at so commonly used is by it being quite close to be? It works well. Yeah. Where are all the other end parameters when they sound like linear function? So why is it not being linear? Oh, yeah. Good point. Yes, you're right. You're right. I mentioned the sense that the parameters are going to be linear here. Yep. Other questions? OK. OK. OK. One last new-ish idea I want to talk about. And that is connection between neural networks and kernel methods. So kernel methods, we talked about this very briefly at the beginning of the lecture. So the kernel method, outflow, or prediction, is going to look like h theta of x, theta transpose 5x. So we're linear in parameters here, but not in x. Yeah? Everyone agrees? OK. So looking at the penultimate layer, AR minus 1, what if we write it as 5b of x, where, sort of, 5 beta, where our beta is going to be all our parameters? So our parameter is w1 all the way to the penultimate layer, wR minus 1. And also our biases, which are 1 all the way to the r minus 1. OK. And then we can write the prediction from our neural network as w of r, so our last layer. Matrix multiplied with 5 beta of x if we fix our parameters. So we're fixing beta here. And we can add our bias term. OK. So really, this looks pretty much the same. The only difference is within the neural network, 5 beta is actually learned. So the algorithm is looking for the best possible features for this data. Whereas in the kernel methods, we choose the kernel. So there's more of that prior knowledge and prior structure that we're infusing into the algorithm. Whereas here, there's flexibility in that these beta parameters can actually be learned to best fit the data. And because of this sort of structural similarity, the penultimate layer output, a r minus 1, is sometimes called the features or the representation. Within a neural network. And so if you ever hear terms like representation learning or something like that, it's talking about those hidden layers within the neural network and what we're learning there. Any questions here? Yeah, at the back. Yeah, at the back. That line where you say h data of x equals w are 5 or d of data. That's all supposed to be one line, right? Yes. Okay. So the, the, whatever that three letters call this, the only substituent. So it's w are matrix multiplied with phi underscore beta of x plus all of that plus the bias term b are. Is the plus the bias term or part of the. It's not like a subscript at all. No, okay. Thank you. Yeah, sorry. Other questions? No. All right. So today we talked about two different things. We talked about supervised learning with nonlinear models. And what that might look like, what the cost function looks like. And the second thing we talked about are neural networks. How do we construct them? We first started with two neural networks and then expanded that notation to be our layer neural networks. And next time, Tangu is going to talk about back propagation. So how do we actually optimize? How do we perform stochastic gradient descent or any kind of gradient descent in this framework? So how do we compute the.\\n the gradients for the cost function and for the neural network. Any last questions? Okay.\\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data [2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "rbvxV4s_IvBL",
        "outputId": "c657e716-b592-4310-906d-f25df8de0b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 2,\n",
              " 'url': 'https://www.youtube.com/watch?v=gPCd0xx_OYI',\n",
              " 'title': 'Stanford Cs229 Machine Learning I Model-Based Rl, Value Function Approximator I 2022 I Lecture 20.Mp3.Txt',\n",
              " 'transcript': \" So I guess today we're going to do the last lecture on reinforcement learning. And I will probably spend like five minutes to briefly wrap up the whole course, but mostly we're going to talk about reinforcement learning. So this is supposed to be a more kind of introductory lecture on some of the other more advanced topics in reinforcement learning. So I wouldn't talk about a lot about details, but mostly I'm going to define some terms and so that is easier for you to kind of like either take another course on reinforcement learning or read some of the literature yourself. So I guess last time we have introduced the basic concept of MDP, a mark of decision process, that's the main language that people use to think about reinforcement questions. I'm going to start by just reviewing some of the key idea. So we call that you have a MDP mark of decision process. This is kind of like is described by a few important concepts. So one thing is a space space. You have to specify the space space to specify the MDP. You have to specify the action space. And the MDP has this transition probability, which is called PSA. For every S and every A, S is in the state A is action. For every S and A you have this so-called transition probability matrix, transition probabilities, which is to describe what is the probability that if you start with state S and take action A, what is the probability to a ref at a new state. And there is this so-called discount factor gamma and the reward function R. So after specifying these five quantities, you get the MDP. And we also talk about the concept of a policy. So policy is something you are trying to learn from interacting with the system, the environment. You are trying to learn the so-called policy, which is a function that maps from the state and action. So this policy tells you what you do, which action do you take when you see a state S. So pie of S is the action you take when you are at the state S. And we also introduced these two concepts, two types of value function. So the first type of value function is the value function of the state S. So this is the value of the state S and the policy pi. So this is the expected reward, expected future payoff of executing the policy pie from state S. You keep taking action from the policy pi, you start with state S, and then you compute what is the total future payoff in expectation and that's the pie of S. So and we also discussed this so-called V star of S. This is oblivious to the policy pi. This is asking, what's the maximum possible reward you can get from starting from state S. So you maximize over all possible policies and you maximize the V pi of S. And the maximum of this process, the arg max of this is the optimal policy you care about. You want to find out what is the optimal policy. So I think we probably didn't have time to define this formula last time. So the optimal policy pi star is the so-called arg max pi V pi. And this is actually, there's a unique pi star that maximizes the V pi for every S. Because the policy itself is already a function of S. So you're finding a policy that maps the function as to the action. You already can take different actions for different state S. So and this is one way to define this and another way to define this is the following. So this is another way to define the optimal policies. You say that this is the greedy policy with respect to V star. So this is the alternative definition of the optimal policy which is defined to be pi star of S is defined to be the best action you take such that you maximize your future payoff. What's your future payoff? The future payoff is equals to R of S plus the payoff you get from the future steps, which is gamma times this P as prime. This is sum over S prime. This is the probability you see S prime after take action A, which is the variable here. And then you times V star S prime. So this part is the expected reward. The best reward you can get after you take action A. You take action A. You have some chance to wrap S prime and you multiply the best payoff you can get after you're after starting from S prime. And this is why this is the best possible expected payoff after you take action A. And this is the payoff you get at state S. So the total thing is the best payoff, including the current payoff, the current return, the best future payoff if you take action A. And you maximize over A and that's the best policy. The best definition of the optimal policy. So because this is already the optimal choice, you are thinking about the optimal choice for all the future steps and then you take action A, it is the optimal for this step, taking into account the future steps and that's the optimal policy for the state S. Any questions? And sometimes this is the way to find out the optimal policy because if you find out what's the V star, then you can find out the optimal policy because you just take the grid policy with respect to V star. And we also introduced this important concept of Bellman equation, which is the main tool that we use to find out to compute V pie and V star. So for V pie, if you're given pie, then the Bellman equation for V pie, the Bellman equation for V pie is equals to this. So V pie of S is equal to R S plus Montgomery times this. Right, so most of the Bellman equations, you can pretty much verify it intuitively yourself, right? So because what is the reward, the payoff when you are state S, accessing policy pie, you first look at what's the current reward for this step and then you create what's the future reward. The future reward can be computed by considering all different possible outcomes of executing pie of S, right? So if you apply pie of S, then you have some probability of S prime and you might have to apply that probability with the payoff you get after arriving at state S prime. And this is one of the important things here was that this is actually linear in the variable V pie. So linear in this in a variable V pie 1 up to V pie, I think I used M as the number of total states. So this is a linear equation of these variables so you can solve the linear equation by an linear system software. And we also introduced this Bellman equation for V star, which is of a familiar form, but the difference is that now you don't have to apply, you have to maximize the action. So you have RS plus a max, you take the best possible action that maximizes the future reward. Right, so now this is not a linear system of equations in terms of V star, but you can use the so-called, the algorithm we introduced last time was this, each of algorithm that you do the Bellman update each of the way, you can do this each of algorithm to find out the V star. And the question so far, this is basically a review of the last lecture. So okay, so so far we have deal with, you know, in the last lecture we have deal with no dynamics. So all of this, right.\\n So we have described the algorithm in so and so forth. Everything was under the assumption that the algorithm, so basically the algorithm to solve the v pi or the algorithm to solve v star, the iterative algorithm. I guess I'm not sure whether you still remember the algorithm. The algorithm here was just something very simple. So you take a loop and you just to say, I'm going to update v. I have a working memory for v. I update v like a v as updated to be something like rs plus max. You just compute the right hand side and then with the v plane here and then you update the left hand side with itself. So this is called the value iteration, the algorithm called value iteration. So both the value iteration algorithm and the algorithm that solved the linear system equation in this case. Both of these two algorithms are assuming you have a known dynamics. So the PSA is known. All the family of PSA is known in both of these two algorithms. Because you have to compute PSA. So in our language, you are saying that this means that you have the known transition dynamics or the known like environment. That's how people refer to these kind of settings. But in reality, what happens is that this PSA is not known anymore. So for example, sometimes you do know it. For example, suppose you consider this is a game like playing gold. You are playing the gold or chess. So you do know the rules of the game. You know what happens if you play action, a, what will happen next. So you're going to move each of the PS in some way. So you know the rules, then in those cases, PSA is not. But in many other cases, the transition dynamics is not known. So for example, when you control the robot, so in some cases, you probably know a little bit about if you control this, the robot would move forward. But sometimes if you're doing the low level control, you are changing the joint of the robotic arm or the hand, your robotic hand. You don't exactly know how the everything moves exactly. You probably have some rough sense, but you never are able to model them exactly. Actually, this is a challenge. So this is actually the reason why now people are using more and more learning techniques. So I think in the early days, I think, for example, there was a company called Boston Dynamics. So what they do is they basically just use rule based, so basically they build this PSA. They try to figure out from physics what exactly the dynamical systems should they look like. And then they build their policies based on that dynamical system. But these days, I think people are kind of like a list trying to apply more learning techniques because there is no way you can figure out exactly what PSA is just from the physical rules. You have to use some kind of learning based technique. Sometimes also it involves interaction with environments. For example, suppose I have a robot that is moving on this carpet, then the speed will be different from the robot moving on the hardwood floor. So the other environments also part of the environment, so then you can never model everything perfectly. You would never know the texture of the floor exactly. So that's why we have to learn the dynamics to some extent. So I think that's the real problem in reinforcement and where the dynamics is unknown. So when you don't have the dynamics, what can you do? So you have to know something. You have to somehow have some information about dynamics. So the typical assumption, which is that the PSA, this is unknown. But you have to give a state S and action A. We can sample S prime from this transition dynamics. Basically, we can just try the real world. We can just say, I'm going to try my action A in a real world and see what's the next S prime is. The S prime will involve a lot of stochasticity. There's randomness, but you're going to observe one random sample from this transition dynamics. So that's why when people call sample complexity, it means that how many times you have to try this. But for how many state and action you have to try to see S prime by just tried in a real world. So that's how people generally learn. So you learn by interacting with the environment by trying all these actions and you somehow learn the dynamics in some way. So that's the basic assumption. And then there are two types of algorithms in reinforcement learning that are the most popular. I think most of the algorithm can be either categorized into one of these groups. So one type of algorithm is called model-based RL. So here the model means the dynamic model means the dynamic model or the transition dynamics. So as the name some will suggest, basically, model-based RL means that you explicitly learn the transition dynamics. How do you learn it? That there are multiple variants. It depends on the situations, depends on how complex the dynamic is. But the transition dynamics are the transition probabilities. Are probabilities? I guess they mean exactly the same thing. They probably just always mean exactly the same thing. But sometimes people have different terms. So basically, you learn this PSA or especially, you build a model to describe this PSA. And you learn this model from the samples. The samples are the data you learn from. And then you build some approximate PSA from the samples. And that's typical type of like a table type of model-based RL algorithm. So from samples. So there is another type of algorithm which is called model-free RL. I don't think there is really a precise definition of any of this. But in some sense, the model-free RL, I would just say, is a negation of this. So you don't explicitly learn a transition probability. So just that doesn't learn the transition. So it sounds a little bit kind of like, if you don't have any context, this sounds might be a little bit tricky because how come you don't learn the dynamics, but still learn the policy. So it's possible. For example, sometimes you can just directly optimize this without learning the dynamics. So you can probably just use some kind of like a stock cut. So there are ways to not learn explicit dynamics. Of course, eventually, any algorithm needs to somehow have some understanding about dynamics internally in some sense. But you don't have to express it, build one. So for example, one possible option is just that you optimize this function vPi over the policy pi. Suppose you can somehow take winning the set over policy pi, then you can avoid dealing with the dynamics, where you don't use the biomein equation. You just somehow compute the derivative of this respect pi. To some of the buzzwords, some of the algorithms, the Q learning is one type of algorithm. Another type of algorithm is called policy gradient. So I don't think we have time to discuss any of this model free algorithm. I just want to write them down here just so the buzzwords so that if you happen to kind of like came across them, then you know they are model free algorithm. In some of the quarters, we do cover this. Some of the quarters have well-to-mort lectures. Depending on how many holidays they are. So another kind of like some of the definition of terms people use here is that there is something called when you say table or case, or a table or RL, this means that you have discrete state space, discrete action and state space. So in other words, the size of the state space is finite. And the size of the action space is also finite. And this and actually in-\\n In some sense, what is finite or not probably is not the most important thing. The real important thing is that the state and the action space are not too big. They are not like a building or something. They are something that is reasonable. In the last lecture, we are basically assuming this. We assume that the state space has an interest. We didn't talk that much about action space, but we implicitly say that. Actually, all the algorithms required that action space to be somewhat going to find out. You can see that this linear system solve algorithm. If you solve the linear system equations, what are the variables? The variables are the V pi 1 up to V pi n, where n is the number of states. If n is infinite, you cannot solve this linear system equations. You have infinite number of variables. Even if n is not infinite, even if n is something like a super big, like a exponentially big or something like a building, then you cannot really afford time to solve this system equations. In some sense, the most important thing is that you really don't want to have. If you are a time blocker, you are implicitly assuming that the state space is not huge. But as you can see, sometimes the state space is just have to be infinite or very big, because the state space is continuous. That's another case where you have continuous state space. Sometimes you have continuous action space as well. For example, the state space is something like Rd. You have a D-dimensional vector to describe the state. Typically, the action space is smaller than the state space. Maybe the action space is something like Rk, where K is smaller than D. Sometimes D can be like a hundred, or maybe sometimes even more than a hundred. Action space typically, if it's continuous, then K probably would be 5, 10, something like that. Sometimes you have the combination, so you have continuous state space, but finite action space that's also possible. For example, if you, for example, one typical case where you have continuous state space, but finite action space is a tower game. The state space is this pixel space where you see the pixels that is shown to you. And actions are actually finite. You just have a few buttons and maybe like some kind of handle you can choose to play. So the action space is somewhat finite. All right. So these are just some kind of like terms just in case they are useful. And we will read some of the other books or literature. Okay, so then in the next 20 minutes, I'm going to discuss how do you do the model, maybe in the next 30 minutes, how do you do the model based RL? Follow the tabular case. So basically you can see that their model based model free and tabular continuous, it's kind of like you have two, like four combinations. And we're going to do the model based plus tabular. So, and this is actually not very hard. So what you really want to do here is that basically model based tabular, you want to learn an explicit model that kind of like a somewhat similar to the true model PSA. So what you have is that you have a collection. So suppose we have a collection of trajectories. And forgot whether I defined trajectories, these trajectories are just a minor sequence of like state actions. So suppose you say you have some state as zero. Maybe let's say you start from the state as zero. And you take some action, maybe A zero. And you arrive at S1. And you take some action A2. And you arrive at S2. So and so forth. So this is the one trajectory, a sequence of state actions. So far I didn't really tell you how I got this trajectory. But I'm going to talk about how do you learn the transition from some given trajectories. So suppose I give one trajectory. And often you need more than one trajectory. So I would say after I take a bunch of steps, maybe I take two steps, I reset. So I reset. And then I get another trajectory. Maybe I call this trajectory as zero one, A zero one. After superscript just to indicate that this is the first trajectory. And then I reset. I get a new initial state. And I call this as zero two. And I apply A zero two. And then I get a bunch of trajectories. So I get a bunch of trajectories. Here the subscript is indexing the time. And the superscript is indexing which trajectory you are in. And then how do you estimate the transition dynamics? Recall that all of these state and actions are discrete variables. Because I'm in a type of case. So basically I just have to ask the question. So basically I just have to estimate PSA as prime. What's the chance to start with S and take action A to an RF as prime? So this is kind of like in some sense the problem is the same as some of this. I think we discussed this generative learning algorithm where we have this advanced model. Where everything is kind of counting based. So basically you can compute the maximum likelihood of this transition. You view this as a parameter. So this is something you want to learn. This is a parameter. And then you try to find out the maximum likelihood estimate for this parameter. And it turns out that it's just as usual it's the most kind of natural choice. Basically you just count on the frequency to see this. You say in the denominator you say I look at how many times. Like we took action A at state S. So you basically look at all the cases where take action A and state S. And then in the numerator you count how many times we took action A at, okay I guess maybe I'm a little too wordy here. So basically the number of times if you take action A and state S and you're RF as prime. So the denominator is the total number of times you take the action A at state S. And the numerator is how many among all of these occurrences of S and A how many times you indeed are RF as prime. And then that's your transition probability. That's your S-minit transition probability. This is an estimate for PSA. Right, so any questions over? And once you have this, it's just a counting based algorithm. You just count how many fractions you really are RF and S-prime. Among all the S-A how many fractions of those you know are RF and S-prime. And that's the empirical frequencies is your estimate for the transition probability. Wait, I'm using the right, should use the black color. Okay, so and once you have this tool to estimate the transition probability, then you can have a model based RR algorithm. I'll still use the right if it's okay, I think the black one doesn't seem to be right. So the model based RR algorithm is doing a following. So it's pretty intuitive. So first of all, you initialize some policy pi. Maybe randomly, let's see. Then you have some data set. Initially you have no data. So the data set D is empty. I'm just defining notation based. I'm going to use this data set D some way. So and once you have this, and then what you really do is that you say, I'm going to have two steps. The first step is that I'm going to estimate. I'm going to collect some data. So collect data by executing policy pi. So if you actually put a real environment, you're going to get some samples. That's our assumption. Our assumption is that you are able to get samples from the real environment. You don't know the PSA, but you can get samples from...\\n So you actually are policy pie to get your environments. So basically what you do is you get a family of environment. Sorry, you actually are policy pie to get some samples. And as the samples you got, let's say they are denoted by s01. Something like an api-a01. And then you get s1, 1, so on and so forth. And you have s1, s02. This is the same kind of set of samples here. So you get some samples. And then you add all of these trajectories to D. So D is kind of like a set of data. And then I'm using the board spacing or awkward way. Hard way. I think I'll just do after. So let's say I'm going to... So you get this data, this kind of data, right? So this is a set of data that is kind of like this. So I'm then... So on the second step, this is the first step. So I'm going to add some data. And then in the second step, you estimate... You estimate the PSA using data in the... Okay, so... And let's do PSA as the estimated. Suppose you get some PSA, it is supposed to be estimate for the real transition dynamics. And then in the step C, so you can use, for example, it's value iteration. Or it could be also policy iteration. I guess we didn't have time to discuss policy iteration in the last lecture. So we are interested in reading lecture notes to see what's the policy iteration. But let's suppose you use value iteration to get... to get V star, the value function, of four, the estimated PSA, the estimated dynamics. So you just pretend that the estimated dynamics and then you solve the best policy, the optimal value function for that dynamics. And then you take PSA to be... You take PSA, be the optimal policy for the same... for the estimate dynamics. Okay, so... So are we done? So it sounds like we are done, right? Because we estimate some... It's kind of everything simple, right? You collect some data, you estimate the... the dynamics, and then you get the best policy of... one of the estimated dynamics. But actually, what you really have to do is... you have to take... you have to have another loop... outer loop that repeats this process. So what you really need to do is you take... have to take a loop. And... So that after you... you have some policy pie, you want to collect some more data using the current policy pie. Initially, the policy pie was random. And you collect data from the random policy. And after you get some policy pie, then you should take another loop to collect more data. And then we estimate your transition dynamics and then recompute your policy. And then you keep doing this. You probably don't have to do a lot of loops, but you have to do some iterations. So the question is why... why you need this loop... outer loop, right? So why we cannot just go with the first dynamics, right? We have estimated it, right? If you ask me one dynamics, you know, if it's actually enough, then why we can... cannot go with that. The reason is that there is... in RL, there is this problem with the... this kind of like so-called exploration, exploitation trade-off, which we have not elaborated. So the... the immediate problem is the following. So it's possible that in the first round, when you collect data, your data is not very good. It's very bad low-coloured data, right? So for example, suppose you want to control a robot. And you initialize your policy randomly. You just do some random... you just push the random buttons, or you control the robots in a random way. Then the data you collect are... are basically just some kind of like a... the robot is just kind of like wiggling around a little bit, right? It doesn't really move much. So the data you collect is actually very... very bad. And then, even you have a lot of data, you see your data quality is not good enough, just because the robot doesn't really do much. And then your estimate dynamics is also not going to be good enough. And then your policy is also not going to be good enough. So what you really want is that you want to do this iterative... so that next round, when your policy is kind of like reasonably okay, you collect some higher-order higher-coloured data. And then you do this again, and then your policy becomes even better, and then you get even better higher-coloured data. So that's why you won't have this loop. Another example is the following. So suppose you have... this is another example. Suppose for example, let's say... I guess you probably... some of you have used this kind of like a automatic robot to clean the... to do the cleaning for the house, where you have this small... like a vacuum... like a robotic vacuum that you can... that can move in your house, right? So if you have used that, I think how it works is that it first kind of like expires your whole... whole room, and to try to figure out what your room looks like. And then the next round is... it's kind of like... do some kind of like... take some trajectories to kind of clean your room, so that it covers every part, right? So something like that. However, but if you think about this, suppose you have... for example, say something like... you have a... like a big room, and then you have a small room adjacent to it, right? So you have some robot that kind of tries to clean the room, and never gets through the room, right? So what if you... at the beginning, your robot only kind of goes to this part, right? So it just... in the first round, your policy just only look at this room. Then your dynamic model will only be able to... only is only accurate for this room, right? You only know what's... what's happening in this room, what's the chairs, what's the... what's the stairs, or other kind of like so... so far, so and so forth, right? So... and... but you don't know anything about this one. So... so that's why you cannot... so that's the... there's a typical creative situation where the... data of the... the quality of the data is not good enough. Because your... your quality of the data doesn't even cover some part of the room. So then you're... if you don't do anything special, then your robot wouldn't have incentive to go to this room, because the robot doesn't even know... the existence of this room, in some sense. So... so this is actually even more challenging in your case, because here... even you just do this loop, you wouldn't be able... necessarily... wouldn't be able to kind of like figure out... this small room, because... beginning... at the beginning, you just... you just only see the large room, and you never look at the small room, and then you... then you figure out a... often policy to clean the large room, and you still don't know the existence of the small room. And you just keep doing this, eventually you just only kind of clean the large room, and you just never know the existence of the small room. So... so in these kind of cases, you need even something more than this, kind of algorithm, to be able to work. So... and typical, this is called... this is a phenomenal called exploitation... versus exploration. So exploitation... basically means that you believe your current transition dynamics. You just... strongly believe that your current transition dynamics... your current kind of understanding about the world, the environment, right? And you just try to find out... optopolicy for that... for the current understanding of a world. And exploration means that you try to explore different kind of strategies... to see whether you miss anything in this world, right? So in this case, you know, maybe you missed the small room, so you want to do exploration to figure out the existence of the small room. And exploitation really just means that you just... basically do the best thing for the current map. So... so as you can see, you know, you need some exploration to kind of... at least covered in the entire kind of like... the entire world, so you know, like the existence of any other options. So... so typically, if you really run this kind of reinforcement... I... learning algorithm, you have to add some randomness in the policy pie... so that you can have some exploration. Right? So you don't want to just always...\\n in every run you just always collect data from the policy pie that is optimal for the current environment. You also want to have some exploration by adding some randomness. So basically, what you really do is that when you collect data, you add some by actually pie with some randomness. So in this case, you have some small chance to go into the small room so that you can see the small room. And then you figure out you should actually clean that small room with some kind of like a trajectory with some actions. So maybe another example is that, for example, suppose you don't figure out which restaurant you want to go in Palato downtown. So suppose you just suppose so far you know two restaurants and you know one of them is better than the other for you. And the exploitation would mean that you just always go to the better restaurant for your taste, right? And then you just keep going to that better restaurant for you. However, you may also consider some exploration because there are many other restaurants in Palato and you don't know the existence of them either. Or you don't know whether they are good or bad. You don't know their taste, whether they are taste-fate-tube. So exploration means that you should try some of the other restaurants even at a risk that those restaurants are not as good as the one you have known. But you want to try more, try to kind of explore those restaurants. And exploitation means that you just believe that, okay, there's nothing I should explore anymore. I just believe in the current evaluation of all the restaurants. I just take the best one and keep going to that best one. So, and there is a truth of because if you keep doing exploration, then you keep trying all different restaurants, then you have to whether you are going to find some restaurants that are not very good. And you're going to suffer, you're going to say, okay, this doesn't worth the money. You're going to have some bad energy in some sense. But on the other hand, if you only do exploitation, you're going to miss all the opportunities. So it really depends on how. And if you really go into the RLA literature, there are different ways to trade off these two things. Depending on how confident you are with each of the choices, you may decide to explore it more or you might decide to explore more. Okay, but I think we are not going to have enough time to go into the details. There's a huge literature here. Even just when you talk about this going to restaurant thing, which doesn't have a sequential aspect. You just go to the restaurant and have lunch or dinner. There is no sequential decision. You still have to think about the exploitation and the exploration trade off. So it's kind of like to do it optimal that you have to be somewhat careful. Okay, any questions so far? So we are doing the exploration. So like, the way we are being back and standing about the world, is it more of the variety of old things to try and find a right to do? Yeah, so I guess maybe you're asking about, you know, how do we do exploration? So what's the guiding principle for doing exploration? And it seems to suggest that when principle could be that you only want to explore when you can get to collect more information. Yes, I think that's basically, it's pretty much like what you said. But sometimes random actually conserve that need. So if you just do random participation of your current option, typically you get some, you get actually good amount of information. But of course, in some other cases, you have to directly go for those kinds of uncertain places. Actually, you are exactly right. So for the type of RL case, typically what people do is not just random exploration. What people do is you say, you take those actions that are most uncertain for you. So suppose you have some action that you don't know what outcome would be. You have no idea what outcome would be. Or you have very little idea, you have very huge uncertainty about what outcome would be. You try those actions more as exploration strategy. But for the continuous state space, right? So I think it turns out that people, most of the algorithm works are kind of like a local randomized exploration. You don't try some crazy option. You try in your neighborhood. I think that's actually probably make a lot of sense. In those cases, we have so many different actions. So for example, if you think about your current planning, like if you really have, suppose you, in theory, you have really, really a lot of actions you can try. Instead of being a Stanford, you can try to be a professional soccer player. So you can be a musician. You can be a many different. There could be many things. You are very uncertain about some of those probably. I wouldn't know what if I tried to be a musician. What would happen? But I think we have so many actions. This is not 100% true. We talk about technical details. But we have so many actions. I think somehow the algorithms, most of the working algorithms, tries to explore locally. So for example, I'm a student here at Stanford. And then I try something similar. Maybe going to intern at Google, or maybe trying to try in gradal school or something like that. But I wouldn't try something completely different. There is no, we don't have a really strong theory to say exactly what you should do. So this is a mixture of some theoretical explanations, some empirical observations. Okay, so I'm going to use the rest of the 40 minutes, 35 minutes to talk about continuous state space. So I have talked about model based arrow. I'm going to talk about model based plus continuous state space. And the idea is pretty much similar. It's just that you have to somehow, you have to deal with the continuous state space. You will see there is some challenge. So, I think this is a really interesting area. At least after I learned it, I feel like it has a lot of things to do with your life decision, of course you can only 100% trust the algorithm. It's not like you should implement the algorithm in your life decisions. But there is some insights theory that is useful for the general. You can model your life as a reinforcement in algorithms. So it's just that one difference is that in a real life, you have much more information. So in the theoretical formulation, you are only collecting information from the samples. So you know nothing about the environment at the beginning. And anything you have to try it out. If you don't know anything about PSA, you have to try it out. And sometimes you can try more and sometimes you can try less. But you still have to try. In left decisions, in many cases you don't have to try. So you can try to understand what the outcome is. And I feel it's pretty similar. Just my two cents. So I guess what we do is continuous state space. Continuous. So one easy case to start with is when D is two, suppose you have the state space is only dimension two. I think when this case, basically a state space is a two-dimensional plan. You have like maybe like a two axis. And one way to do it is that you just discretize your state space into discrete variables. So before each of the state is like two real number, but then you say I'm going to discretize the state space. There's some boundary, of course, not be too big. And then you discretize something like this. And then for every cell, you say all the states, there are infinite number of states in this each of the cell. But you say all the states in that cell is going to be treated as one state. Just because they are all pretty much similar. So as long as you have like fine enough granularity here, then you can basically treat every cell as a single state. And suppose you have like granularity, absolutely, you have to have one of absolute square, one of absolute choices for the first one, the one of absolute choices for the second one. So you have one of absolute square choices of states. And you can probably take absolute to be something like 0.01. I don't know exactly, but you're going to get a rough, either a reasonable number of states. Maybe quite a lot, but not like maybe a thousand or something like ten thousand, but it wouldn't be too bad. So that's the easy choice. However, this doesn't really work for when you dimension it's higher than two. I think when you dimension three, it already becomes tricky because...\\n If you think about your discretizing the three-dimensional space, then say suppose D3, and you do this one of epsilon, kind of like each of this size of each of this cell is epsilon, then you need one of epsilon to the power of 3 states. I guess it depends on what epsilon you choose. But if you choose epsilon to be something at 0.01, then you have like 100 to the power of 3, that's like a million, which is already a lot. So maybe sometimes it's still OK, but generally when D3 is already kind of tricky. And then you can see this doesn't scale very well, because if you have D for any D, this would be one of epsilon to the power D. And when D is 5, basically, it's kind of impossible, completely impossible. So we need our other approach for, but actually just to clarify, so when D is 2, actually, this is actually a pretty good idea, because it's simple and clean, and we don't have to deal with any other complications. The only thing is that you have one of epsilon's square states, but there's no any other complications. It's actually a pretty good solution. I think it probably should work in most cases. So when D is more than 3, it's going to be a problem. Basically, what we do is we're going to redesign everything that we have discussed with continuous state space in mind. So I guess there are two questions. One question is how to learn P and C for continuous state space. And then question 2 is that how do you do the value iteration? Both for continuous state space. So for question 1, so let's discuss each of them. And the basic idea is that you try to extend what you have done to the continuous state space in some way. So we're going to question 1. So how do you do it? The first question problem is that how do you even represent the PSA? So now you have infinite number of S here. So before for every S and A, you have a vector to represent. And the right, so for every S A, this PSA is a distribution. And it's basically a vector over impossible choices if I'm missing number of states. But now you have infinite number of S here, or maybe exponential number of S there. And for every PSA, this vector is actually a very high dimensional vector, maybe a exponential dimensional vector, or infinite dimensional vector. So how do you even represent this? So the idea is that you can change the way to represent it. You don't represent this, you can do the following. There are many ways, but this is one way that is probably common. Learning on dynamics. So what you do is you first say I'm going to model this process as prime is summed from PSA by assuming as prime is equals to FSA plus some noise. This is one option, not only option, but one option is you assume that S prime is computed by applying some functional S and A and then I some noise. That's my way to sample S prime from this distribution. So this is a way to define the distribution. The distribution basically has mean FSA and some Gaussian has some variance, like the same as the cosine. So this will give you a random variable S prime given S and A. So and this FSA, let's say maybe FSA is deterministic. This is just some function you want to learn. And this part is the noise that gives you the stochasticity. Maybe let's say cosine is maybe from some 0 with some covariance sigma. So sometimes I guess probably I've seen FC that this is almost the same as what we do with a supersering. We just treat this as a supersering problem. So S prime is my label as an A are my inputs. So I'm just trying to predict my label from the inputs. And the way I model this is I model this by some function plus noise. And then you can do maximum likelihood. And the maximum likelihood is just the square loss. So and you learn that you learn this model F by some square loss. So for example, so you have to introduce some parameterization for F. So for example, F could be a linear model. Suppose you say you have some parameter A and B. And your F could be just A as plus B in a way. So this could be your F, which is paramount by A and B. So A and B are parameters as and there are inputs. So you just have this linear model. I think this is called linear dynamical model. So this is linear model. And another option is that you say I'm going to say FSA is equals to maybe you can use the same idea as the feature. Like when you do the kernel, you can say this is something like A times FIOS plus B times. I forgot what this is called. Like this is called. You just have some other feature sometimes. So both of this two fees, these are some features. So this is like what we did with kernel method. So you introduce some features and then you are linear in a feature space. Of course, you can also say that FSA, so I guess here the parameter is A and B as well. So you can also say my FSA if you have paramount, I suppose, some theta is a neural network applied on ISNA something like this. And this neural network is maybe say paramount, I suppose theta. So you just say ISNA are concatenated as inputs of a network and you apply this network with paramount theta and the output will be my FSA. In each of these cases, you can model your S-prime like this and then you can try to find out and this becomes a surprisingly problem. So what I mean is that once you have the paramount position, so then you can say you can, the learning loss function is that, so suppose you have some beta. Suppose the beta are something like, I guess I've written this several times, I see your one, A is your one, nice one, one, so on and so forth. So you have a bunch of trajectories. Sorry, I messed up the indexing. So you have these trajectories and then you break these trajectories into three tuples. So we mean that you view this, you are a collection of three tuples. So you say you have S01, A01, comma S11. So this is the first three things here. And you view this as the input and this as the so-called label or output. And then you say, I'm going to have these three things, which is S11, A11 and S12. So this again is the input and this is a label. And you do this for every three tuples in every trajectory. So you basically get a sequence of flycars.\\n three tables. So you get eventually you get as t minus 1, n, n is the number of trajectories, a t minus 1, n. I guess the lot of indexing here, but basically just the view average, three concatrix, three consecutive kind of like numbers as a table, and you view the first as an a as the input, and the odd comma is the odd input. Something like this. OK, so you have a little side of this, right? So this is the side of size n times t. n is the number of trajectories, t is the length of the trajectories. And then you do a surprise learning. So you just use the surprise learning. So you do some kind of regression, let's say. You say I'm going to minimize over my parameter, maybe that's called theta. And I minimize this over, I minimize the loss over all data points. So what is the loss? So there is a i, there is also a t, i is indexing the trajectories and t is indexing the time set. And every time you want to predict what you want to predict as t plus 1 in the i-t directory, using this function f theta as t i, a t i. So this is the input of this surprise learning problem. You apply the model, and then you try to match it with the output, the label of this problem. And here I'm using the L2 norm because the label is a vector, so in many of the cases you see this parenthesis square because in those cases when you do this typical surprise learning problem, your label is a real number, right? House price prediction, right? So the label is a house price, which is a real number. But here the label is a vector, it's the same. You just do the L2 norm square. Sometimes you can change the loss function. You don't have to always use L2 norm square. Maybe you don't even need square sometimes. Oh, you can use other loss L1, some sort of touching. So once you do this, you get a theta. And this f theta will be on model. Any questions? So I think the benefit here is that before you have to specify PSA for every S and A, right, as a vector. So now you learn this function f theta. So the number of parameters is theta. And then for every S and A, you can compute fs A if you know the theta. So that's how you do the model based RL part. That's how you do the model estimation part, how you estimate dynamics. And then you also need to deal with the value iteration. How do you do the value iteration for continuous state space? I don't think I have the math there. So when you do the value iteration, before you are trying to kind of like update the value function for every state or every time. So that's not possible anymore because you have so many states. You cannot update the value function for every state. Actually, it's not even clear how do you even describe a value function. Because before the way you describe a value of functions, for every V star S, for every V star S, I have a number. But before you describe it by listing all the S, for every S, you have a number. That's how you describe V star. But now you cannot really describe it like that. So what you do is you say, I'm going to parametrize the value function by again, kind of like before, buy some kind of like a new I work or linear model. So you can say, I parametrize, I write my Vs as, like something like maybe one choice is that you sense a, this is state address, transpose times some feature of S. So this is a feature and this is the parameter. That's my option. And another option is that you say, my V of S is a new I work. With parameter theta applied on a state S. Right, so then theta is a description of the value of function. And you need to learn theta. Of course, there are other ways to do this. For example, one way to do it is that you can, for example, design some right, the right features using physical intuitions. Sometimes you know that some coordinates, only meaningful when it combines with other coordinates in some meaningful way. So I think some mitch of this could also work because you could design some features and then use these features as inputs to a new I work. But generally you just want to have a parametrize form. So after we have the representation of the value of function and the next question is how do you do the update? Right, so before what we did was that, so we call the update was something like V as is up to be something like RR plus gamma max A. Right, that's what we did. So we have some working value for V and we compute the right hand side of the Bellman equation and we update the V with the right hand side. And then we repeat. So, but you cannot do this because you don't have, before we do it for every S, but that's not possible anymore. So what we do is we try to make this true for the S we have seen. So basically for continuous space, so for the continuous case, we just try to ensure the Bellman equation for states that we have seen. You don't need to ensure this for every state S anymore. You just ensure it for states you have seen. And if you just want to do that, then you can do some kind of loss function to ensure that. So let me elaborate on what do I mean here? So, so you first, the first step is the following. So we estimate the right hand side of the Bellman equation for states, say, S1 up to S1. So I haven't told you exactly how I got this state, right? So suppose I got some states that I have seen, right, in like an algorithm. And I want to only ensure this Bellman equation, you should be able to do this. So, I want to ensure that this is the right hand side of the Bellman equation. So, I want to ensure this Bellman equation, you should be able to do this. So, I want to ensure this, you should be able to do this or somewhat encourage it. They are the same. Only for this kind of choice of states, S is equal to one of this. That's my compromise because I cannot do it for every state. So, what I do is that I try to first compute the right hand side. So, how do I get the right hand side for every state S? So, what I do is I just, so basically I want to compute R as I plus this max thing. But the problem is that here I have a sum over S prime. Again, that's again a lot of different choices of S. So, what I do is I'm going to first turn this into an expectation. You write this as expectation of V as prime. And S prime is samples from P as I. So, after you have the expectation, you can use an empirical sample to estimate this quantity. So, basically what you do is you say, so for every, by the way, I think I forgot to mention one thing, which is that now I'm talking about continuous state space, but finite action space. Just this is a slightly simpler question than both of my continuous. Just because I don't want to overcomplic too much.\\n So, so the, so it's continuous state space and finite action space. So, what I do is I have first estimate this by sampling some as prime. And then I take the max because you have finite number of states, action space, actions, you can just take the max. So, what you do is you say for every a, you get k samples. Let's call it as one prime up to s k prime. These are samples from this transition dynamics PSA. PS, S i, A. Right, so you, you, on the set S i, you try to action A and you see what is the outcome. You have a, a bank of random outcome. And then you see defined Q a to be, R i, plus one over k times this average. You use the empirical average basically. Right, the empirical average of p, v, i, s j, s j prime. So this is supposed to estimate, this is supposed to estimate R as, I think I'm missing a gamma here, sorry. It's supposed to estimate R as, plus, R as i, plus gamma, expectation, v, s i. Right, so I'm supposed to use this to estimate this without a max. And then I take the max, I call, Y, i, to be the max of this Q a. So then this is supposed to estimate this one. So Y i is supposed to estimate this quantity. And for every i, I have estimate. Right, so for every i, I have estimate for the right hand side of this gamma equation. And then I ensure that this gamma equation to be somewhat, correct for all the i's that I have considered. So, so step b, I need to enforce, um, like, v as i, to be close to yi. All right, because you know, we call that we have spent so much effort to compute this yi, it's y is supposed to be the right hand side of the biome equation evaluate at si. And then one of these to be close to the left hand side. And how do I do that? I do that by say I'm computing theta, to be arc max of this loss function that encourages this. And the loss function is simple, just some L2 loss. Say, I take the average over all the possible i's i's. And let's say, v, um, my v as i is parametrized by some say, new i's work like this way. So let's don't talk about new i's works, but it works for anything. So say, this is a neural network, neural net, with theta applied on si minus yi square. So basically you want this new i to work to output, the right value function that matches the target, the target is the right hand side of the biome equation. Actually, you know, in a, in a, in a, in the RL papers, you do call this target. So this is a target you want to kind of match. And, and you want to choose the theta, update the theta such that your left hand side, which is this new right work on si to match the target. And that's your theta that you got in this step. And again, you have to do, it's a value iteration, you have to iterate because if you get theta this way, you have to iterate to, or recompute your, your right hand side and then update the life hands side, where you call it, you do the development, the value iteration, you compute the right hand side and you update the life hands side, you do this iteratively. So, so eventually you also have to have a iteration, which is, you say, you, I see, so you iterate between these two steps. So, you say you have a loop, but I think there's a little bit, to that specify everything. Yes, I think I specify, okay. So, this is the loop, maybe sorry, let's, okay, yes, so, I'm a little bit, let's just save some space before. So, let's say this is, I have a loop here. Right, so, but this is not still not enough, because this loop is doing what? This loop is only doing the value iteration for this S1 after S1, right, I haven't told you even how do you get S1 after S1, right, it's just a bunch of states that you have seen. So, and also even you, like you can update, you can do this for every S, or value iteration is not enough, because our model based algorithm has something even an author layer of the value iteration. So, you're asking the model and do value iteration, and then you ask the model again, you do value iteration. Or you have to do another author loop to update your samples, right, so because when you do the model based algorithm, you already have a loop outside the value iteration. So, this is a loop point value iteration, and then we have another loop outside it, which is supposed to do the, to iteratively update the model. So, basically you have another loop. And in this loop, you collect some data. Say S1 after S1, you collect this data from current policy, right, you collect the data, and then you do the value iteration on this data, and then you collect it again, and you do value iteration. So, this is how it may in the model based our algorithm for type block case. Right, because for the type block case, we also have this author loop, where you collect data, and you do value iteration, and you collect data, you do value iteration. So, okay, so I think I'm missing in the more most. You collect data, you collect data, and also you need to also, in this also loop, you also have to estimate dynamics. Collect data, my bad. So, collect data may be one, and two, you estimate dynamics, and then three, you do the value iteration, and the value iteration consists of another loop, which is this. I see some confusing faces. So, basically, I think I reached that, oh, actually, it was part of here, right? So, this was the part that we deal with the type of the case. So, we have the, the two steps, I think maybe I actually renamed them, and I think that it's a little bit more confusing. So, basically, I think I reached that, oh, actually, it was part of here, right? So, this was the part that we deal with the type block case, right? So, we have to, the two steps, I think maybe I actually renamed them as one, two, and three. And there was one step that was erased, which is the first step, which is collect data. Right? So, before we do the type block case, you repeat between three, you alternate between three steps, collect data, estimate dynamics, value iteration. And now, for the, for the, the continuous space, continuous space, number one is to the same. Number two was done by this part of the board, where we learn this, you know, with the supersonic learning. And number three is done by here, this part of the board, where we do this A and B step, the A and B to kind of like to do the value iteration. So, so number three is this part, where we do the value iteration. And, and eventually we have to do a loop for this one, two, three, on top of this one, two, three. Okay, I guess that's all for today. And for this whole course, I guess, you know, we have covered, you know, supersonic learning, unsuppressed learning and reinforcement learning. Yeah, and we try to kind of like cover a little more and more deep learning these days. But also like some of these methods are,\\n I think these are the foundations of machine learning. So I hope you had some fun with the course. Thanks.\\n\"}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "# Replace 'path_to_your_transcripts' with the actual path where your transcripts are stored in Colab\n",
        "transcript_dir = '/content/files/transcripts/lectures'\n",
        "\n",
        "# Create a zip file of the transcripts directory\n",
        "shutil.make_archive('transcripts', 'zip', transcript_dir)\n",
        "\n",
        "# Download the zip file to your local machine\n",
        "from google.colab import files\n",
        "files.download('transcripts.zip')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "MCT5iWSMvXtG",
        "outputId": "42e94355-b2b4-4975-f4a5-ffebc7523ad5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_4abd623f-a5f9-4cb1-b118-bd8ecad3c67c\", \"transcripts.zip\", 400918)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now textsplitter"
      ],
      "metadata": {
        "id": "RppOWsalK2Gf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tiktoken.encoding_for_model('gpt-3.5-turbo')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTJZNwt9LtyL",
        "outputId": "4b1ea275-8dc7-46d0-ef1d-c93bbcc21ec4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Encoding 'cl100k_base'>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tiktoken\n",
        "\n",
        "tokenizer = tiktoken.get_encoding('cl100k_base')\n",
        "\n",
        "# create the length function\n",
        "def tiktoken_len(text):\n",
        "    tokens = tokenizer.encode(\n",
        "        text,\n",
        "        disallowed_special=()\n",
        "    )\n",
        "    return len(tokens)"
      ],
      "metadata": {
        "id": "flHMXxUBLu9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=400,\n",
        "    chunk_overlap=20,\n",
        "    length_function=tiktoken_len,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")"
      ],
      "metadata": {
        "id": "1wlIhCP2K5u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chunks = text_splitter.split_text(data[6]['transcript'])[:3]\n",
        "chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wyolLgHyIyOz",
        "outputId": "79c76d99-6b05-4e38-b483-1fef3fd3b7b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"Hello, so welcome to the next section of CS229. So what we're going to talk about in the next series of about four lectures is the start of unsupervised and kind of less supervised learning and I'll make that concrete. And kind of the plan is what you're going to see is you're going to see a bunch of things that look like various different ways of dealing with this fundamental problem of what do we do when we don't have labels, right? So we're first going to get an algorithm called k-means and then we're going to look at this algorithm called GMM, this Gaussian mixture model, those will both happen today. And we'll try and put those algorithms on kind of solid footing in the maximum likelihood framework, okay? We'll then see a couple of more algorithms that have to do with this unsupervised way of viewing the world. One of them you're going to use in your homework called ICA. It's actually the reason I teach it. It's kind of a fun algorithm. It's a weird bit of setup, but it's probably people's favorite homework problems when we look through the kind of feedback. It's a fun problem if you remember the cocktail problem from the first day where you have people talking in a party and you have microphones scattered around the edge and you want to know who said what. You want to do what's called sometimes source separation and understand the sources. So we'll do that in the ICA section. And then we'll talk about a more advanced topic called weak supervision. weak supervision is industrially used to create large training sets for big deep learning models, which you've just come out of that. But these are labels that are lower quality than the traditional supervised labels. And then finally we'll talk about self supervised learning, which is really exciting and is one of the big revolutions in machine learning where we train on something simple like predicting the next word. And if we train on\",\n",
              " \"in machine learning where we train on something simple like predicting the next word. And if we train on enough data, we can use it for all of these other sometimes called downstream tasks, okay? So that's kind of the program for the next four or five lectures. And today we're going to start with those basics. Okay, so we're going to start with the basics as unsupervised and work our way up to pretty modern stuff. And I will say historically, I would say five years ago, I kind of didn't like teaching on supervised because it felt kind of squishy and weird to be honest with you. It didn't have the beautiful theory or maybe even 10 years ago. Didn't have the beautiful theory of supervised learning where you could say like this is the right model and we go find it in a lot of cases. But that's been where almost all of the research activity, not only in my group, but kind of from AI over the last three or four years has been in this unsupervised realm. So we'll start with some of the classics and get our way to something really, really excited. So the classic and probably an algorithm you already know or probably you can guess kind of how it works is this algorithm called k-means, right? And then we'll get to these other ones. But this is the one we're going to start with first. So what's the difference? So in the supervised setting, right, we get points. And the key issue is that the points come with labels. You have labeled these plus and these minus as we were doing. And we would draw a line or a boundary in between them. That was the way we formalized a wide variety of learning tasks. Right? And the point is, is those pluses and minuses, those are labels, right? An unsupervised started in this setting. I give you the points, but I don't tell you any labels underneath\",\n",
              " \"started in this setting. I give you the points, but I don't tell you any labels underneath the covers. Now there are many things on the spectrum between, I give you the labels perfectly to, I don't show you any information about the labels and I just show you the data points. And we're going to talk about that spectrum. But now we're going to start in the cleanest setting and unsupervised, where we just see those points. Now, the thing that you should calibrate here is like, what can we expect as an answer? So in the supervised setting, as I said, it was super clear what we wanted. Like we could talk about what this line is. And we can go deeper and deeper into like why that's the right line, right? That's the right separating hyperplane. In the unsupervised case, it's necessarily squishing. We'll talk about the ways in which it's squishy. And what I mean by that is it's harder in some sense. So unsupervised learning is harder. And what I really mean by that, then supervised. What I really mean by that is we have to allow stronger assumptions. Okay, stronger assumptions. Right, so one of the things that kind of pass by you without thinking about it too much in the supervised setting is you're like, there's just some data and there exists a separator. There exists some class. That's pretty weak for what we had to assume about the data. For unsupervised, we're going to have to assume there's some kind of latent or hidden structure. And a lot of the conversation is, hey, if that structure is there, can I provably recover it? That's the kind of thing that we're going to do. And we're going to trade off kind of assuming more about our data and trying to find it robustly, okay? And now compared to supervised, we're also going to accept\"]"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Emeddings"
      ],
      "metadata": {
        "id": "-pFPAcGjL0se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import OpenAIEmbeddings\n",
        "\n",
        "model_name = 'text-embedding-ada-002'\n",
        "\n",
        "embed = OpenAIEmbeddings(\n",
        "    model=model_name,\n",
        "    openai_api_key=openai_api_key\n",
        ")"
      ],
      "metadata": {
        "id": "KGQW_tc5LyJX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Indexing"
      ],
      "metadata": {
        "id": "0rCtnmF7Okop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import Pinecone\n",
        "pc = Pinecone(api_key=api_key)"
      ],
      "metadata": {
        "id": "1HOlJC_oL90J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pinecone import ServerlessSpec\n",
        "\n",
        "spec = ServerlessSpec(\n",
        "    cloud=\"aws\", region=\"us-east-1\"\n",
        ")"
      ],
      "metadata": {
        "id": "VeuFwD4aL9ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "index_name = 'transcription-index'\n",
        "existing_indexes = [\n",
        "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
        "]\n",
        "\n",
        "# check if index already exists (it shouldn't if this is first time)\n",
        "if index_name not in existing_indexes:\n",
        "    # if does not exist, create index\n",
        "    pc.create_index(\n",
        "        index_name,\n",
        "        dimension=1536,  # dimensionality of ada 002\n",
        "        metric='dotproduct',\n",
        "        spec=spec\n",
        "    )\n",
        "    # wait for index to be initialized\n",
        "    while not pc.describe_index(index_name).status['ready']:\n",
        "        time.sleep(1)\n",
        "\n",
        "# connect to index\n",
        "index = pc.Index(index_name)\n",
        "time.sleep(1)\n",
        "# view index stats\n",
        "index.describe_index_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QUmVrDuL3rd",
        "outputId": "f7f30da2-e73a-4cff-8c86-cc9380b907a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {},\n",
              " 'total_vector_count': 0}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "from uuid import uuid4\n",
        "\n",
        "batch_limit = 100\n",
        "\n",
        "texts = []\n",
        "metadatas = []\n",
        "\n",
        "for i, record in enumerate(tqdm(data)):\n",
        "    # first get metadata fields for this record\n",
        "    metadata = {\n",
        "        'id': str(record['id']),\n",
        "        'source': record['url'],\n",
        "        'title': record['title']\n",
        "    }\n",
        "    # now we create chunks from the record text\n",
        "    record_texts = text_splitter.split_text(record['transcript'])\n",
        "    # create individual metadata dicts for each chunk\n",
        "    record_metadatas = [{\n",
        "        \"chunk\": j, \"transcript\": text, **metadata\n",
        "    } for j, text in enumerate(record_texts)]\n",
        "    # append these to current batches\n",
        "    texts.extend(record_texts)\n",
        "    metadatas.extend(record_metadatas)\n",
        "    # if we have reached the batch_limit we can add texts\n",
        "    if len(texts) >= batch_limit:\n",
        "        ids = [str(uuid4()) for _ in range(len(texts))]\n",
        "        embeds = embed.embed_documents(texts)\n",
        "        index.upsert(vectors=zip(ids, embeds, metadatas))\n",
        "        texts = []\n",
        "        metadatas = []\n",
        "\n",
        "if len(texts) > 0:\n",
        "    ids = [str(uuid4()) for _ in range(len(texts))]\n",
        "    embeds = embed.embed_documents(texts)\n",
        "    index.upsert(vectors=zip(ids, embeds, metadatas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "08f7661011da49c086b897a769dd540b",
            "731c15c5b25b4ad1a3e976105e2224e1",
            "61da003cebdc47e5bdb6e6e17c5eb435",
            "815039f9efa446d9b1493d04684a43c8",
            "2522185eae224455811b934e5fce035f",
            "8c1b6d0e9415405dbf892ad6dd920881",
            "3eba3a6eda984f15a8d1ff0ef7f3f885",
            "7837979659b240e699ce7ae72f353c18",
            "ea20cc704bd54d85913c8e14734fbe79",
            "b53e2b9ae8e8405a945a64daf91fdd05",
            "402704b3bc304ba4974f448d9646b3e4"
          ]
        },
        "id": "0x7zP6jKNPN3",
        "outputId": "5df21648-553e-47b2-b18d-91c48ad71ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "08f7661011da49c086b897a769dd540b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index.describe_index_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xgka-8rhO_EP",
        "outputId": "476f491b-10a4-45f9-80cd-b049c677e860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dimension': 1536,\n",
              " 'index_fullness': 0.0,\n",
              " 'namespaces': {'': {'vector_count': 754}},\n",
              " 'total_vector_count': 754}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating a Vector Store and Querying"
      ],
      "metadata": {
        "id": "uAvF0FsxPBsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.vectorstores import Pinecone\n",
        "\n",
        "text_field = \"transcript\"  # the metadata field that contains our text\n",
        "\n",
        "# initialize the vector store object\n",
        "vectorstore = Pinecone(\n",
        "    index, embed.embed_query, text_field\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mm6MxDO-O_be",
        "outputId": "8936d5db-227c-4440-b4ee-b2c85e5567ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/pinecone.py:68: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Why do you split testing and training data?\"\n",
        "\n",
        "vectorstore.similarity_search(\n",
        "    query,  # our search query\n",
        "    k=3  # return 3 most relevant docs\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwGFLoMaPID-",
        "outputId": "789447d6-6e95-4a01-c750-4a80d9b9dcbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'chunk': 32.0, 'id': '17', 'source': 'https://www.youtube.com/watch?v=NirZnqwYfYU', 'title': 'Stanford Cs229 Machine Learning I Feature ⧸ Model Selection, Ml Advice I 2022 I Lecture 11.Mp3.Txt'}, page_content=\"sometimes they give you a deviation, right? So they say, this is the validations set, this is the training set, sometimes they just release the, the total, all of them to you. And then you can, you can divide yourself. You know, even they release in this format, you can redevide them, you know, whatever you want to do. So let's say suppose you have divided all, you know, all those training examples, you do two sets, you can do whatever kind of like, whatever kind of like optimization you want. So, and I think typically they do have like a, that's a validation set, which is used for the, for computing the scores on the leaderboard. And then there's a leaderboard, which kind of like tells you how well you are doing against others, at least 10 temporarily.\"),\n",
              " Document(metadata={'chunk': 41.0, 'id': '17', 'source': 'https://www.youtube.com/watch?v=NirZnqwYfYU', 'title': 'Stanford Cs229 Machine Learning I Feature ⧸ Model Selection, Ml Advice I 2022 I Lecture 11.Mp3.Txt'}, page_content=\"this will give you a lot of intuitions on, you know, what data you should use and what kind of models you should use. And do this at every stage because, you know, like, for example, we would really do them. And this is also the reason why we want to build some tools to look at your data conveniently. So, sometimes, like if you just look at it once, then sure, then you can just maybe print out something, right? So, but if you want to look at many times, then you should have some convenient tools, which actually eventually will reinforce and let you to more likely to look at your data. So, I think at least in research, I also realized this. So, if the data is very hard to visualize, then people are less likely to to visualize the data. So, sometimes it requires an investment so that you can have this tool so that in the future, you have less of a cost to look at your data. And you should do this at every stage, in many cases. So, and this is, I guess, you know, this is about domain knowledge sometimes, you know, some of the data requires expertise, right? Like, to know, so, I think there are some examples, you know, in the slides, which I removed it just to save some time, but that ensures, in sometimes, you know, for example, if your data is crafted, like experts, only experts can know, like, for example, you have multiple data, only experts can know that your data are crafted, but like from a machine learner perspective, the data looks fine. So, and we talked about Trun and Test the split. So, so this, of course, is something important for you to, to do. And in practice, you know, it's a lesson clear, then, then in research, right? Because in research, you already got, sometimes you\"),\n",
              " Document(metadata={'chunk': 45.0, 'id': '17', 'source': 'https://www.youtube.com/watch?v=NirZnqwYfYU', 'title': 'Stanford Cs229 Machine Learning I Feature ⧸ Model Selection, Ml Advice I 2022 I Lecture 11.Mp3.Txt'}, page_content=\"So your final goal is to predict the price in the future. So that's something you just don't have at all. Now, suppose you have data between 2020 and 2020. So you have these 20 years of data. So how do you do the trend validation split? Should you just do a random split or should you do some other things? So one possible option is that you should split into, for example, 2000 to 2015. That's the trend. And 2015 to 2020, that's the validation. Why you argue that? Why that's a possible option? Possibly just because the last five years is more predictive of the future than the early years. So, you know, I don't necessarily say, I'm not necessarily saying that this is the only option or the best option, but this is at least something to consider. So this would kind of like a, kind of like a, this is not what we do in research. And the reason is just because, you know, you care about the performance in the future, which is something you don't have access to. So I guess this is. So the best split is that you use the first 50 days to predict the last 50 days. So, okay, and create a specification, right? So I think this is mostly related to like how do you kind of like define what you want to predict? And what's the, what's the kind of the goal, right? So in many cases, you can use machine model in many different ways from what you wanted to use it. And also you care about kind of different kind of like perspectives. So for example, you know, what is a span, right? So like the definition of span sometimes, you know, are different, between different people, right? So like maybe do you think, like an ad, right, from some, from, from say Google,\")]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative Question-Answering"
      ],
      "metadata": {
        "id": "IrqFuCLlPu2L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.agents import initialize_agent, Tool\n",
        "\n",
        "# Initialize the language model with OpenAI API key and parameters\n",
        "llm = ChatOpenAI(\n",
        "    openai_api_key=openai_api_key,\n",
        "    model_name='gpt-3.5-turbo',\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "# Initialize ConversationBufferMemory for managing memory\n",
        "memory = ConversationBufferMemory()\n",
        "\n",
        "# Create the RetrievalQA instance with the language model and retriever\n",
        "qa = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vectorstore.as_retriever(),\n",
        "    memory=memory  # Integrate the memory with RetrievalQA\n",
        ")\n",
        "\n",
        "# Define a tool for the React agent to use the RetrievalQA instance\n",
        "tools = [\n",
        "    Tool(\n",
        "        name='video_transcript_retriever',\n",
        "        func=qa.run,\n",
        "        description='Searches and returns excerpts from the transcript of the user-uploaded video.'\n",
        "    )\n",
        "]\n",
        "\n",
        "# Initialize the React agent with the language model, tools, and memory\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent_type=\"conversational-react-description\",\n",
        "    memory=memory\n",
        ")\n"
      ],
      "metadata": {
        "id": "phS_yqTcPprv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eda8c757-9cf3-4aa2-8794-347766b2d666"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.3.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langsmith.evaluation import evaluate, LangChainStringEvaluator"
      ],
      "metadata": {
        "id": "f-pbN5YgVV30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output1 = qa.invoke(query)\n",
        "output1['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "IonjuyIwQOTA",
        "outputId": "62d7c60e-479b-458a-b8df-4ada18a65e0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The reason for splitting testing and training data is to evaluate the performance of a machine learning model. The training data is used to train the model, while the testing data is used to assess how well the model generalizes to new, unseen data. This helps in determining the model's effectiveness and its ability to make accurate predictions on new data.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query2 = \"Summarise all of the text in 300 words\"\n",
        "\n",
        "output2 = qa.invoke(query2)\n",
        "output2['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "5jom0t3JVNdb",
        "outputId": "5d814925-5637-4aff-8d68-9daec7e2326e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The text discusses various applications of machine learning models, particularly in generating coherent stories, answering questions based on given passages, unscrambling words, and solving simple numerical problems. The model learns from a large unlabeled dataset and can perform these tasks effectively. It also mentions the importance of academic integrity in homework assignments, emphasizing independent work and proper citation of discussions. The text highlights the course project component, encouraging group work on machine learning applications or algorithms. It mentions the diverse range of project topics seen in previous years and the flexibility to explore different areas of interest. Additionally, the text briefly explains the approach of converting text into vectors using a vocabulary list, illustrating how words are represented as zero-one vectors in a high-dimensional space. The discussion also touches on the alphabetical order of words in a vocabulary list and the process of vectorizing text data for machine learning tasks. Overall, the text provides insights into the practical applications of machine learning models, academic integrity guidelines, and the project component of the course.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Evaluations on Queries**"
      ],
      "metadata": {
        "id": "ZTI1MCxkWNeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.evaluation import load_evaluator\n",
        "evaluator = load_evaluator(\"labeled_criteria\", llm=llm, criteria=\"correctness\")"
      ],
      "metadata": {
        "id": "l2Dh62o7Pxby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query3 = \"What are the names of the lecturers?\"\n",
        "\n",
        "output3 = qa.invoke(query3)\n",
        "output3['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "jMVWWo-wdyfD",
        "outputId": "67932c34-2070-4aad-d1c8-17a9362355b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The names of the lecturers mentioned in the context are Tong Yima and Chris.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output3['result'],\n",
        "    input=query3,\n",
        "    reference=\"Tong Yima and Chris\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-7N3EQZEV-NO",
        "outputId": "ac19bd11-d8c8-4852-87b0-32fb0202baf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Correctness:\\n- The submission mentions Tong Yima and Chris as the names of the lecturers.\\n- The reference also lists Tong Yima and Chris as the names of the lecturers.\\n- Therefore, the submission is correct, accurate, and factual.', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query4 = \"what is linear regression?\"\n",
        "\n",
        "output4 = qa.invoke(query4)\n",
        "output4['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "wwHeeMIBU2gz",
        "outputId": "a65bc9d2-4fa0-4487-8a65-7d369790d558"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Linear regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a straight line to the data points. It is commonly used for predicting continuous outcomes and is a fundamental technique in statistics and machine learning.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output4['result'],\n",
        "    input=query4,\n",
        "    reference=\"In machine learning, linear regression is used to predict a continuous outcome variable based on one or more predictor variables by fitting a linear relationship. It finds the line of best fit that minimizes the sum of squared differences between observed and predicted values.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VkqmR-ZnVSIW",
        "outputId": "b1343d77-1577-40ba-bf98-b856d7096aea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Correctness:\\n- The submission correctly defines linear regression as a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a straight line to the data points.\\n- The submission accurately states that linear regression is commonly used for predicting continuous outcomes and is a fundamental technique in statistics and machine learning.\\n- The submission accurately describes the purpose and process of linear regression in machine learning.\\n\\nBased on the comparison with the reference provided, the submission is correct, accurate, and factual.\\n\\nTherefore, the submission meets the Criteria.', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query5 = \"What is the type of generative learning algorithms discussed?\"\n",
        "\n",
        "output5 = qa.invoke(query5)\n",
        "output5['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "QZeq52QVU_u_",
        "outputId": "6a332f7c-4f1a-48d0-addf-a8d1abf02166"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The type of generative learning algorithms discussed are Gaussian discriminative analysis.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output5['result'],\n",
        "    input=query5,\n",
        "    reference=\"Gaussian Discriminant Analysis (GDA) \"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69E0E8Y0VPy8",
        "outputId": "cd42d419-c2ba-4635-a701-51ef9b0486b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Correctness:\\n- The submission states that the type of generative learning algorithms discussed are Gaussian discriminative analysis. However, the correct type should be Gaussian discriminant analysis, not Gaussian discriminative analysis. This is an incorrect statement.\\n- Therefore, the submission does not meet the criteria of correctness.\\n\\nN', 'value': 'N', 'score': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query6 = \"What is the difference between unsupervised learning and supervised learning?\"\n",
        "\n",
        "output6 = qa.invoke(query6)\n",
        "output6['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "7qjMKTZSY2ZO",
        "outputId": "0c46e05c-81d0-4008-98bc-1dfff78d0e93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The main difference between unsupervised learning and supervised learning is the presence of labels in the data. In supervised learning, the data comes with labels that the model learns to predict, such as class labels or target values. On the other hand, in unsupervised learning, the data does not have any labels, and the model needs to find patterns or structures in the data without explicit guidance from labeled examples.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output6['result'],\n",
        "    input=query6,\n",
        "    reference=\"Unsupervised learning finds patterns or structures in unlabelled data, while supervised learning uses labelled data to train models for predicting outcomes.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iV2roamsZWo_",
        "outputId": "c8d96926-4b30-4d1f-85dd-0c83234843c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Is the submission correct, accurate, and factual?\\n- The submission correctly states that the main difference between unsupervised learning and supervised learning is the presence of labels in the data.\\n- It accurately describes supervised learning as having labeled data that the model learns to predict, and unsupervised learning as lacking labels.\\n- The submission is factual in stating that in supervised learning, the model learns to predict labels, while in unsupervised learning, the model finds patterns or structures in the data without labels.\\n\\nTherefore, the submission meets the criteria.\\n\\nY', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query7 = \"Differences between reinforcement and unsupervised/supervised learning?\"\n",
        "\n",
        "output7 = qa.invoke(query7)\n",
        "output7['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "W34vHynrY2UV",
        "outputId": "ffeea4de-2640-4ef2-bc7e-d29f591c725b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Reinforcement learning involves making sequential decisions to maximize rewards in an environment, where the agent learns through trial and error. It focuses on learning optimal actions based on feedback received from the environment. On the other hand, supervised learning involves learning from labeled data, where the algorithm is trained on input-output pairs to make predictions. Unsupervised learning, like clustering algorithms, deals with finding hidden patterns or structures in unlabeled data without explicit feedback or guidance. The key difference lies in the nature of the learning process and the type of information available during training.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output7['result'],\n",
        "    input=query7,\n",
        "    reference=\"Reinforcement learning trains agents to make decisions by maximizing rewards, while supervised learning uses labeled data for predictions and unsupervised learning identifies patterns in unlabeled data.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "InvpynIBZwyZ",
        "outputId": "26e531a4-e481-4b3e-ff8a-e3d85d7f0131"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. The submission correctly explains that reinforcement learning involves making sequential decisions to maximize rewards in an environment through trial and error, while supervised learning involves learning from labeled data and unsupervised learning deals with finding hidden patterns in unlabeled data.\\n2. The submission accurately describes the key differences between reinforcement learning, supervised learning, and unsupervised learning.\\n3. The submission provides factual information about the nature of the learning process and the type of information available during training for each type of learning.', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query8 = \"What is an example of using  AI systems in healthcare for heart conditions?\"\n",
        "\n",
        "output8 = qa.invoke(query8)\n",
        "output8['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "id": "TPdW0LVrY2Gp",
        "outputId": "16485eda-5b86-4352-daf9-68b7041913fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'One example of using AI systems in healthcare for heart conditions is the development of a computer vision system that analyzes ultrasound videos of the human heart to assess different cardiac conditions in patients. This system was developed at Stanford and has been deployed in healthcare settings to help healthcare professionals in diagnosing and monitoring heart conditions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output8['result'],\n",
        "    input=query8,\n",
        "    reference=\"Computer visions system for assessing heart conditions.  The idea is that there are ultrasound videos looking at the human heart.  A system was developed to read these videos and assess different cardiac conditions of a patient.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfIsQ3jbaPm_",
        "outputId": "1f27206c-c7e4-41bf-c112-567aba8a3499"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Correctness:\\n- The submission accurately describes the use of AI systems in healthcare for heart conditions, specifically mentioning the development of a computer vision system that analyzes ultrasound videos of the human heart to assess different cardiac conditions in patients.\\n- The submission also correctly states that this system was developed at Stanford and has been deployed in healthcare settings.\\n- The information provided in the submission aligns with the reference provided.\\n\\nTherefore, the submission meets the criteria.', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query9 = \"What is high level summary of backpropogation?\"\n",
        "\n",
        "output9 = qa.invoke(query9)\n",
        "output9['result']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "MEtxiX-0ZgUj",
        "outputId": "3f128e6e-a2b6-45a8-cc22-c4cbf5f5c31f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The high-level summary of backpropagation is that it is a technique used to compute the gradient of the loss function for a neural network. This gradient calculation is crucial for updating the parameters of the network during training, typically using algorithms like stochastic gradient descent. The process involves computing the gradient of the loss function with respect to the network's parameters by propagating the error backwards through the network layers. This allows the network to learn and improve its performance over time.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output9['result'],\n",
        "    input=query9,\n",
        "    reference=\"Backpropagation is an algorithm used in training neural networks, where the error is calculated at the output and propagated backward through the network to update the weights. This process uses the gradient descent optimization technique to minimize the error by adjusting the weights iteratively.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O8-cJHgMbjwA",
        "outputId": "ad1f655f-ccf8-41bf-cbe4-c9b4d02fce2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': \"- The submission accurately describes backpropagation as a technique used to compute the gradient of the loss function for a neural network.\\n- The submission correctly states that the gradient calculation is crucial for updating the parameters of the network during training, typically using algorithms like stochastic gradient descent.\\n- The submission accurately explains the process of computing the gradient of the loss function with respect to the network's parameters by propagating the error backwards through the network layers.\\n- The submission correctly mentions that backpropagation allows the network to learn and improve its performance over time.\\n\\nTherefore, the submission meets the Criteria.\", 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Conciseness"
      ],
      "metadata": {
        "id": "Wn9iNe7ReEhe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = load_evaluator(\"labeled_criteria\", llm=llm, criteria=\"conciseness\")"
      ],
      "metadata": {
        "id": "BwQUBUGAeG_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output3['result'],\n",
        "    input=query3,\n",
        "    reference=\"Tong Yima and Chris\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKDXiDKyeMVV",
        "outputId": "4dca84b1-8380-4dfb-b757-4d0d36e23496"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Is the submission concise and to the point?\\n- The submission mentions the names of the lecturers, Tong Yima and Chris, which directly answers the question without any unnecessary information.\\n- The submission is concise and to the point.', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output4['result'],\n",
        "    input=query4,\n",
        "    reference=\"In machine learning, linear regression is used to predict a continuous outcome variable based on one or more predictor variables by fitting a linear relationship. It finds the line of best fit that minimizes the sum of squared differences between observed and predicted values.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0353ca53-1136-4fe3-c97e-fdee4ea10435",
        "id": "6esCT7nEeiOE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': 'Step by step reasoning:\\n1. The submission provides a clear and concise definition of linear regression.\\n2. The submission does not include any unnecessary information and directly addresses the question asked.\\n3. The submission is focused on explaining the concept of linear regression without going into unnecessary details.\\n\\nConclusion: The submission meets the criteria for conciseness.\\n\\nY', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output5['result'],\n",
        "    input=query5,\n",
        "    reference=\"Gaussian Discriminant Analysis (GDA) \"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4HxPYf_ejaQ",
        "outputId": "9f57a511-075b-4675-cca3-c5bdb2687269"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Conciseness:\\n- The submission directly answers the question without any unnecessary information.\\n- The submission is clear and to the point, mentioning Gaussian discriminative analysis as the type of generative learning algorithms discussed.\\n- The submission is concise and does not include any extra details that are not relevant to the question.\\n\\nTherefore, based on the criteria of conciseness, the submission meets the criteria.\\n\\nY', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output6['result'],\n",
        "    input=query6,\n",
        "    reference=\"Unsupervised learning finds patterns or structures in unlabelled data, while supervised learning uses labelled data to train models for predicting outcomes.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2SLIteIejXy",
        "outputId": "439b7e0e-0e68-4936-a1de-01340c5eb94c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': 'Step by step reasoning:\\n1. The submission provides a clear explanation of the main difference between unsupervised learning and supervised learning.\\n2. The submission is concise and directly addresses the difference between the two types of learning.\\n3. The submission does not include any unnecessary information and focuses on the key point of the presence of labels in the data.\\n\\nTherefore, the submission meets the criteria for conciseness.\\n\\nY', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output7['result'],\n",
        "    input=query7,\n",
        "    reference=\"Reinforcement learning trains agents to make decisions by maximizing rewards, while supervised learning uses labeled data for predictions and unsupervised learning identifies patterns in unlabeled data.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Euo-yeaRejVI",
        "outputId": "83ea5d24-2238-4bfc-b538-c5a12dac8d84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': 'Step by step reasoning:\\n1. The submission provides a concise explanation of the differences between reinforcement learning, supervised learning, and unsupervised learning.\\n2. The submission covers the key points of each type of learning in a clear and straightforward manner.\\n3. The submission does not include unnecessary details or elaborations, sticking to the main differences between the learning types.\\n\\nConclusion: The submission meets the criteria for conciseness.\\n\\nY', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output8['result'],\n",
        "    input=query8,\n",
        "    reference=\"Computer visions system for assessing heart conditions.  The idea is that there are ultrasound videos looking at the human heart.  A system was developed to read these videos and assess different cardiac conditions of a patient.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_3Aib5veqLd",
        "outputId": "9b34c420-4250-4776-bb7e-351734f9cf04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. The submission provides a clear and concise example of using AI systems in healthcare for heart conditions. It directly mentions the development of a computer vision system that analyzes ultrasound videos of the human heart to assess different cardiac conditions in patients. The information is presented in a straightforward manner without unnecessary details.\\n\\nTherefore, the submission meets the criteria for conciseness.\\n\\nY', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output9['result'],\n",
        "    input=query9,\n",
        "    reference=\"Backpropagation is an algorithm used in training neural networks, where the error is calculated at the output and propagated backward through the network to update the weights. This process uses the gradient descent optimization technique to minimize the error by adjusting the weights iteratively.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HS-q8m-2eqIe",
        "outputId": "727d0e84-0627-47f2-fb10-71fadc395e3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': 'Step by step reasoning:\\n1. The submission provides a high-level summary of backpropagation in a clear and concise manner.\\n2. The submission explains the purpose and process of backpropagation effectively without unnecessary details.\\n3. The submission stays focused on the main points without going off on tangents.\\n\\nConclusion: The submission meets the criteria.', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Coherence"
      ],
      "metadata": {
        "id": "HKUd1b35e5Re"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluator = load_evaluator(\"labeled_criteria\", llm=llm, criteria=\"coherence\")"
      ],
      "metadata": {
        "id": "NI-q_iQyfD9L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output3['result'],\n",
        "    input=query3,\n",
        "    reference=\"Tong Yima and Chris\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7IEFFwt6fR8A",
        "outputId": "3f3f82cb-ff9c-44b8-ea21-09a42c463229"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Coherence:\\n- The submission states that the names of the lecturers mentioned in the context are Tong Yima and Chris.\\n- The reference provided also includes Tong Yima and Chris.\\n- The submission is clear, well-structured, and organized in presenting the information.\\n- The submission is coherent and directly addresses the question asked.\\n\\nTherefore, based on the coherence criterion, the submission meets the criteria.', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output4['result'],\n",
        "    input=query4,\n",
        "    reference=\"In machine learning, linear regression is used to predict a continuous outcome variable based on one or more predictor variables by fitting a linear relationship. It finds the line of best fit that minimizes the sum of squared differences between observed and predicted values.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQWFmm1OfR4K",
        "outputId": "f84d48d1-fc8b-428d-c8c8-a5eca7caf0ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Coherence:\\n- The submission provides a clear definition of linear regression as a statistical method used to model the relationship between variables.\\n- It explains the purpose of linear regression in predicting continuous outcomes and its significance in statistics and machine learning.\\n- The submission is well-structured, starting with a definition and then providing additional information about the application and importance of linear regression.\\n\\nBased on the step by step reasoning, the submission meets the criteria for coherence.', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output5['result'],\n",
        "    input=query5,\n",
        "    reference=\"Gaussian Discriminant Analysis (GDA) \"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iXkf0YNofR1n",
        "outputId": "e2be256a-f20e-4093-8bb7-e7ad5a752c10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Coherence: \\n- The submission states that the type of generative learning algorithms discussed are Gaussian discriminative analysis. However, the correct term should be Gaussian Discriminant Analysis (GDA) as per the reference provided.\\n- The submission is clear and concise in its response, directly answering the question asked.\\n- The submission is not well-structured as it contains a minor error in the term used.\\n\\nTherefore, based on the coherence criterion, the submission does not fully meet the criteria.\\n\\nN', 'value': 'N', 'score': 0}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output6['result'],\n",
        "    input=query6,\n",
        "    reference=\"Unsupervised learning finds patterns or structures in unlabelled data, while supervised learning uses labelled data to train models for predicting outcomes.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fdsx1ocfRyO",
        "outputId": "9bd82fb6-ec13-47cc-af43-49a551f7aa09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Coherence:\\n- The submission clearly explains the main difference between unsupervised learning and supervised learning.\\n- It is well-structured, starting with a clear introduction and then providing detailed explanations for each type of learning.\\n- The submission is organized in a logical manner, first discussing supervised learning and then moving on to unsupervised learning.\\n\\nBased on the above reasoning, the submission meets the coherence criterion.\\n\\nY', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output7['result'],\n",
        "    input=query7,\n",
        "    reference=\"Reinforcement learning trains agents to make decisions by maximizing rewards, while supervised learning uses labeled data for predictions and unsupervised learning identifies patterns in unlabeled data.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_YLwZmEfYvp",
        "outputId": "68801d66-b2da-42c2-d8c1-c292502559f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Coherence:\\n- The submission provides a clear and concise explanation of the differences between reinforcement learning, supervised learning, and unsupervised learning.\\n- It is well-structured, starting with a definition of reinforcement learning and then moving on to supervised and unsupervised learning.\\n- The submission is organized in a logical manner, comparing and contrasting the three types of learning methods.\\n- The information is presented in a coherent way, with a clear focus on the key differences between the learning processes.\\n\\nTherefore, based on the above reasoning, the submission meets the criteria for coherence.\\n\\nY', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output8['result'],\n",
        "    input=query8,\n",
        "    reference=\"Computer visions system for assessing heart conditions.  The idea is that there are ultrasound videos looking at the human heart.  A system was developed to read these videos and assess different cardiac conditions of a patient.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zrXjP6iKfYsw",
        "outputId": "100d5407-2471-4a7c-f2c4-562ef5baa32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': '1. Coherence:\\n- The submission is coherent as it clearly explains the example of using AI systems in healthcare for heart conditions.\\n- The submission is well-structured, starting with the example and providing details about the development and deployment of the system.\\n- The submission is organized, with a clear flow of information from the introduction of the example to its application in healthcare settings.\\n\\nTherefore, the submission meets the criteria.', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eval_result = evaluator.evaluate_strings(\n",
        "    prediction=output9['result'],\n",
        "    input=query9,\n",
        "    reference=\"Backpropagation is an algorithm used in training neural networks, where the error is calculated at the output and propagated backward through the network to update the weights. This process uses the gradient descent optimization technique to minimize the error by adjusting the weights iteratively.\"\n",
        ")\n",
        "print(eval_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zUv7BJjdew4t",
        "outputId": "a4cd8177-4f31-4745-fcae-d494c2c397e8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'reasoning': 'Step by step reasoning:\\n1. The submission is coherent as it explains the high-level summary of backpropagation in a logical and structured manner.\\n2. The submission is well-structured as it follows a clear flow of explaining what backpropagation is, why it is important, and how it works.\\n3. The submission is organized as it presents the information in a systematic way, starting from the definition of backpropagation to its application in updating neural network parameters.\\n\\nTherefore, the submission meets the Criteria.\\n\\nY', 'value': 'Y', 'score': 1}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "08f7661011da49c086b897a769dd540b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_731c15c5b25b4ad1a3e976105e2224e1",
              "IPY_MODEL_61da003cebdc47e5bdb6e6e17c5eb435",
              "IPY_MODEL_815039f9efa446d9b1493d04684a43c8"
            ],
            "layout": "IPY_MODEL_2522185eae224455811b934e5fce035f"
          }
        },
        "731c15c5b25b4ad1a3e976105e2224e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8c1b6d0e9415405dbf892ad6dd920881",
            "placeholder": "​",
            "style": "IPY_MODEL_3eba3a6eda984f15a8d1ff0ef7f3f885",
            "value": "100%"
          }
        },
        "61da003cebdc47e5bdb6e6e17c5eb435": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7837979659b240e699ce7ae72f353c18",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ea20cc704bd54d85913c8e14734fbe79",
            "value": 17
          }
        },
        "815039f9efa446d9b1493d04684a43c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b53e2b9ae8e8405a945a64daf91fdd05",
            "placeholder": "​",
            "style": "IPY_MODEL_402704b3bc304ba4974f448d9646b3e4",
            "value": " 17/17 [00:22&lt;00:00,  1.81s/it]"
          }
        },
        "2522185eae224455811b934e5fce035f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c1b6d0e9415405dbf892ad6dd920881": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3eba3a6eda984f15a8d1ff0ef7f3f885": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7837979659b240e699ce7ae72f353c18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea20cc704bd54d85913c8e14734fbe79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b53e2b9ae8e8405a945a64daf91fdd05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "402704b3bc304ba4974f448d9646b3e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}